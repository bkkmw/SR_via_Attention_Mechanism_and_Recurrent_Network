{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "JTtMMAo3sWiR",
        "iCkhjloWNzNv",
        "hbW1R6BCsi26",
        "FE38fMpfNqsh",
        "UXhORBrMmTFl"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "355b033cde6d493681decd1a462f98ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_98c8c77e1344429891d580400f9f9c97",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_2ec99806c2664785ae17c03a1f09f6c6",
              "IPY_MODEL_b4c55f5066fe49c68985304fbd5f83d8"
            ]
          },
          "model_module_version": "1.5.0"
        },
        "98c8c77e1344429891d580400f9f9c97": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "2ec99806c2664785ae17c03a1f09f6c6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_2dae5b2882be4a6ebec5910a76051956",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 553433881,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 553433881,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b418f88ca5284787a9ffd91b6b8885cb"
          },
          "model_module_version": "1.5.0"
        },
        "b4c55f5066fe49c68985304fbd5f83d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a631f4df5e5749d4b0a162aae387a406",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "â€‹",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 528M/528M [00:32&lt;00:00, 17.1MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a3ea0e9fc104d569b3564626d86e4f7"
          },
          "model_module_version": "1.5.0"
        },
        "2dae5b2882be4a6ebec5910a76051956": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "b418f88ca5284787a9ffd91b6b8885cb": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        },
        "a631f4df5e5749d4b0a162aae387a406": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          },
          "model_module_version": "1.5.0"
        },
        "2a3ea0e9fc104d569b3564626d86e4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          },
          "model_module_version": "1.2.0"
        }
      }
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J62dU6Uh3i-K"
      },
      "source": [
        "ARGAN : Attentive Recurrent Generative Adversarial Network\n",
        "for Shadow Detection and Removal"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JTtMMAo3sWiR"
      },
      "source": [
        "# import lib & data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5i1gWeWkNYXt",
        "outputId": "ef78c294-d980-4ab9-bf37-021ee4727ba8"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Apr 12 15:33:23 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.67       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P8    29W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LxjAVH0X1v2m",
        "outputId": "11610d30-69ef-48e7-bb42-bacee5d38e80"
      },
      "source": [
        "# import lib\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import os\n",
        "\n",
        "import torchvision.transforms as transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "from PIL import Image\n",
        "from skimage import color\n",
        "\n",
        "# mount to drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# GPU\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(device)\n",
        "\n",
        "# load images from Google Drive\n",
        "#!ls '/content/drive/My Drive/KU/4/ISTD_Dataset/train/'\n",
        "img_path = '/content/drive/My Drive/KU/4/ISTD_Dataset/train/'\n",
        "test_path = '/content/drive/My Drive/KU/4/ISTD_Dataset/test/'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "cuda:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "axznqdA9baoi"
      },
      "source": [
        "Functions"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Wwqbv6QbcSK"
      },
      "source": [
        "# display image\n",
        "def imshow(image):\n",
        "  # numpy\n",
        "  npimage = image.detach().numpy()\n",
        "  plt.imshow(np.transpose(npimage, (1,2,0)))\n",
        "  plt.show()\n",
        "\n",
        "# Save output tensor as image\n",
        "def save_batch(images, nrow, PATH):\n",
        "  img = torchvision.utils.make_grid(images, nrow=nrow)\n",
        "  img_out = np.transpose(img.detach().numpy().astype('float64'), (1,2,0))\n",
        "  img_out = (255*img_out).astype('uint8')\n",
        "  img_out = Image.fromarray(img_out)\n",
        "  img_out.save(PATH)\n",
        "\n",
        "def save_batch_LAB(images, nrow, PATH):\n",
        "  img = torchvision.utils.make_grid(images, nrow=nrow)\n",
        "  img_out = np.transpose(img.detach().numpy().astype('float64'), (1,2,0))\n",
        "  img_out = color.lab2rgb(img_out)\n",
        "  img_out = (255*img_out).astype('uint8')\n",
        "  img_out = Image.fromarray(img_out)\n",
        "  img_out.save(PATH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pcx8X15kdxRN"
      },
      "source": [
        "Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tv-5A8kYqPjw"
      },
      "source": [
        "# My dataset loading function\n",
        "def make_dataset(root, test) -> list:\n",
        "  dataset = []\n",
        "  # sub folder names of data set\n",
        "  if test is True:\n",
        "    src_dir = 'test_A'\n",
        "    matt_dir = 'test_B'\n",
        "    free_dir = 'test_C'\n",
        "  else:\n",
        "    src_dir = 'train_A'\n",
        "    matt_dir = 'train_B'\n",
        "    free_dir = 'train_C'\n",
        "\n",
        "  # file names of dataset\n",
        "  src_fnames = sorted(os.listdir(os.path.join(root, src_dir)))\n",
        "  matt_fnames = sorted(os.listdir(os.path.join(root,matt_dir)))\n",
        "  free_fnames = sorted(os.listdir(os.path.join(root,free_dir)))\n",
        "\n",
        "  # matching datasets by name\n",
        "  # same fname for triplets\n",
        "  for src_fname in src_fnames:\n",
        "    # source image (image with shadow)\n",
        "    src_path = os.path.join(root,src_dir,src_fname)\n",
        "    if  src_fname in matt_fnames:\n",
        "      # shadow matte image\n",
        "      matt_path = os.path.join(root,matt_dir,src_fname)\n",
        "      if src_fname in free_fnames:\n",
        "        # shadow free image\n",
        "        free_path = os.path.join(root,free_dir,src_fname)\n",
        "        # if triplets exists append to dataset\n",
        "        temp = (src_path, matt_path, free_path)\n",
        "        dataset.append(temp)\n",
        "      # if one of triplets missing do NOT append to dataset\n",
        "      else:\n",
        "        print(free_fname, 'Shadow free file missing')\n",
        "        continue\n",
        "    else:\n",
        "      print(matt_fname, 'Shadow matte file missing')\n",
        "      continue\n",
        "\n",
        "  return dataset\n",
        "\n",
        "\n",
        "class ARGAN_Dataset(torchvision.datasets.vision.VisionDataset):\n",
        "  # ARGAN dataset class composed of 3 func\n",
        "  def __init__(self, root, loader=torchvision.datasets.folder.default_loader,\n",
        "               is_test=False, src_trans=None, matt_trans=None):\n",
        "    super().__init__(root, transform=src_trans, target_transform=matt_trans)\n",
        "    self.test = is_test\n",
        "    # Custom dataset loader for Training\n",
        "    samples = make_dataset(self.root, test=is_test)\n",
        "    self.loader = loader\n",
        "    self.samples = samples\n",
        "    self.trans2tensor = transforms.ToTensor()\n",
        "    # train data list\n",
        "#    self.src_samples = [s[0] for s in samples]\n",
        "#    self.matt_samples = [s[1] for s in samples]\n",
        "#    self.free_samples = [s[2] for s in samples]\n",
        "\n",
        "  # Get single data\n",
        "  def __getitem__(self, index):\n",
        "    # load training data\n",
        "    src_path, matt_path, free_path = self.samples[index]\n",
        "    src_sample = self.loader(src_path)\n",
        "    matt_sample = self.loader(matt_path)\n",
        "    free_sample = self.loader(free_path)\n",
        "\n",
        "    matt = self.trans2tensor(matt_sample)\n",
        "    free = self.trans2tensor(free_sample)\n",
        "\n",
        "    # transform data if required\n",
        "    if self.transform is not None:\n",
        "      # transform for RGB image : Shadow image and Shadow free image\n",
        "      src_sample = self.transform(src_sample)\n",
        "      free_sample = self.transform(free_sample)\n",
        "    if self.target_transform is not None:\n",
        "      # transform for Binary image : Shaode Matte\n",
        "      matt_sample = self.target_transform(matt_sample)\n",
        "\n",
        "    if self.test is False:\n",
        "      return src_sample, matt_sample, free_sample\n",
        "    else:\n",
        "      return src_sample, matt_sample, free_sample, matt, free\n",
        "\n",
        "  # Get dataset length\n",
        "  def __len__(self):\n",
        "    return len(self.samples)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tSE-w5TojPrT"
      },
      "source": [
        "Transforms"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ea1cmMadznH"
      },
      "source": [
        "# image Transforms\n",
        "# image size 128x128 used for training _ from paper\n",
        "img2tensor = transforms.Compose([\n",
        "                                 transforms.Resize(size=(256,256)),\n",
        "                                 transforms.ToTensor()\n",
        "                                 # additional tasks\n",
        "])\n",
        "matt2tensor = transforms.Compose([\n",
        "                                  transforms.Resize(size=(256,256)),\n",
        "                                  transforms.Grayscale(1),\n",
        "                                  transforms.ToTensor()\n",
        "                                  # additional tasks\n",
        "])\n",
        "\n",
        "# Load images\n",
        "batch_num = 4\n",
        "dprow = 2\n",
        "\n",
        "train_img = ARGAN_Dataset(img_path, src_trans=img2tensor, matt_trans=matt2tensor, is_test=False)\n",
        "trainloader = torch.utils.data.DataLoader(train_img, batch_size=batch_num, shuffle=True)\n",
        "\n",
        "test_img = ARGAN_Dataset(test_path, src_trans=img2tensor, matt_trans=matt2tensor, is_test=True)\n",
        "testloader = torch.utils.data.DataLoader(test_img, batch_size=4, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iCkhjloWNzNv"
      },
      "source": [
        "# Check Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WCnwqZ89ij02"
      },
      "source": [
        "Loaded Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "WbJFZccHfKCV",
        "outputId": "3675cf50-16d0-4923-e9cc-91e22195052c"
      },
      "source": [
        "print(train_img)\n",
        "\n",
        "#for i, (src,matt) in enumerate(trainloader):\n",
        "dataiter = iter(trainloader)\n",
        "print(type(dataiter))\n",
        "images, mattes, frees = dataiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(mattes.shape)\n",
        "print(frees.shape)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images, nrow=dprow))\n",
        "imshow(torchvision.utils.make_grid(mattes, nrow=dprow))\n",
        "imshow(torchvision.utils.make_grid(frees, nrow=dprow))\n",
        "\n",
        "#imshow(frees)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-e05f8d009690>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#for i, (src,matt) in enumerate(trainloader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mdataiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrainloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtype\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataiter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9MMB7VuBkpUk"
      },
      "source": [
        "Test Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "id": "N62NsHMbiPIT",
        "outputId": "7666c803-8519-4ca0-bab5-190474e637af"
      },
      "source": [
        "print(test_img)\n",
        "\n",
        "#for i, (src,matt) in enumerate(trainloader):\n",
        "testiter = iter(testloader)\n",
        "\n",
        "images, mattes, frees = testiter.next()\n",
        "\n",
        "print(images.shape)\n",
        "print(mattes.shape)\n",
        "print(frees.shape)\n",
        "\n",
        "imshow(torchvision.utils.make_grid(images, nrow=dprow))\n",
        "imshow(torchvision.utils.make_grid(mattes, nrow=dprow))\n",
        "imshow(torchvision.utils.make_grid(frees, nrow=dprow))\n",
        "\n",
        "#imshow(frees)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-c087567a070e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_img\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#for i, (src,matt) in enumerate(trainloader):\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtestiter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtestloader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'test_img' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hbW1R6BCsi26"
      },
      "source": [
        "# Generative Network"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZWuIDCKzQs0g"
      },
      "source": [
        "Convolutional LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L-KrDsBRJAok"
      },
      "source": [
        "# LSTM layer\n",
        "class ConvLSTM(nn.Module):\n",
        "    def __init__(self, inp_dim, hid_dim, out_dim=None):\n",
        "        super(ConvLSTM, self).__init__()\n",
        "        self.in_dim = inp_dim + hid_dim\n",
        "        self.hidden_dim = hid_dim\n",
        "        # Same output Channel as input Channel\n",
        "        if out_dim is None:\n",
        "            self.out_dim = inp_dim\n",
        "        else:\n",
        "            self.out_dim = out_dim\n",
        "        self.conv_i = nn.Conv2d(self.in_dim, self.out_dim, 3, 1, 1)\n",
        "        self.conv_f = nn.Conv2d(self.in_dim, self.out_dim, 3, 1, 1)\n",
        "        self.conv_c = nn.Conv2d(self.in_dim, self.out_dim, 3, 1, 1)\n",
        "        self.conv_o = nn.Conv2d(self.in_dim, self.out_dim, 3, 1, 1)\n",
        "        self.sig = nn.Sigmoid()\n",
        "        self.tanh = nn.Tanh()\n",
        "\n",
        "    def forward(self, x, c_prev, h_prev):\n",
        "        # input X and hidden state H_prev\n",
        "        xh = torch.cat((x, h_prev), 1)\n",
        "        i = self.sig(self.conv_i(xh))\n",
        "        f = self.sig(self.conv_f(xh))\n",
        "        c = (f * c_prev) + (i * self.tanh(self.conv_c(xh)))\n",
        "        o = self.sig(self.conv_o(xh))\n",
        "        h = o * self.tanh(c)\n",
        "        # C_next : cell output, H_next : hidden state\n",
        "        return c, h\n",
        "\n",
        "    def init_hidden(self, batch_size, image_size):\n",
        "        height, width = image_size\n",
        "        return torch.zeros(batch_size, self.hidden_dim, height, width)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CVr3cQxbaVJ"
      },
      "source": [
        "Generator"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0GVLiJuCkavD"
      },
      "source": [
        "# Conv + BN + LReLU\n",
        "class ConvL(nn.Module):\n",
        "    def __init__(self, inp_ch, out_ch, k=None, s=None, p=None):\n",
        "        super(ConvL, self).__init__()\n",
        "        # (3, 1, 1) default\n",
        "        if k is None:\n",
        "            k = 3\n",
        "            s = 1\n",
        "            p = 1\n",
        "        # default params\n",
        "        elif s is None:\n",
        "            s = 1\n",
        "        elif p is None:\n",
        "            p = 0\n",
        "        self.conv = nn.Sequential(\n",
        "            nn.Conv2d(inp_ch, out_ch, kernel_size=k, stride=s, padding=p),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.conv(x)\n",
        "\n",
        "# ConvT + BN + LReLU\n",
        "class DConvL(nn.Module):\n",
        "    def __init__(self, inp_ch, out_ch, k=None, s=None, p=None):\n",
        "        super(DConvL, self).__init__()\n",
        "        # (3, 1, 1) keep spatial resolution\n",
        "        if k is None:\n",
        "            k = 3\n",
        "            s = 1\n",
        "            p = 1\n",
        "        # default params\n",
        "        elif s is None:\n",
        "            s = 1\n",
        "        elif p is None:\n",
        "            p = 0\n",
        "        self.dconv = nn.Sequential(\n",
        "            nn.ConvTranspose2d(inp_ch, out_ch,\n",
        "                               kernel_size=k, stride=s, padding=p),\n",
        "            nn.BatchNorm2d(out_ch),\n",
        "            nn.LeakyReLU())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.dconv(x)\n",
        "\n",
        "# Attention Detector : 10 (Conv + BN + LReLU) layers\n",
        "class AttDet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(AttDet, self).__init__()\n",
        "        self.block = nn.Sequential(\n",
        "            ConvL(3, 8), ConvL(8, 8), ConvL(8, 16), ConvL(16, 16),\n",
        "            ConvL(16, 16), ConvL(16, 32), ConvL(32,32),\n",
        "            ConvL(32, 64), ConvL(64, 64), ConvL(64, 64)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = self.block(x)\n",
        "        return out\n",
        "\n",
        "# Removal Encoder : 8 Conv + 8 DConv +3 Conv Layers\n",
        "class REncoder(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(REncoder, self).__init__()\n",
        "        # CONV LAYERS : extract feature\n",
        "        self.conv0 = ConvL(3, 64, 3, 2, 3)\n",
        "        self.conv1 = ConvL(64, 128, 3, 2, 2)\n",
        "        self.conv2 = ConvL(128, 256, 3, 2, 2)\n",
        "        self.conv3 = ConvL(256, 512, 3, 2, 2)\n",
        "        self.conv4 = ConvL(512, 512, 3, 2, 2)\n",
        "        self.conv5 = ConvL(512, 512, 3, 2, 2)\n",
        "        self.conv6 = ConvL(512, 512, 3, 2, 2)\n",
        "        self.conv7 = ConvL(512, 512, 3, 2, 2)\n",
        "\n",
        "        # DECONV LAYERS : generate image with feature data\n",
        "        self.dconv0 = DConvL(512, 512, 4, 2, 2)\n",
        "        self.dconv1 = DConvL(512, 512, 4, 2, 2)\n",
        "        self.dconv2 = DConvL(512, 512, 4, 2, 2)\n",
        "        self.dconv3 = DConvL(512, 512, 4, 2, 2)\n",
        "        self.dconv4 = DConvL(512, 256, 4, 2, 2)\n",
        "        self.dconv5 = DConvL(256, 128, 4, 2, 2)\n",
        "        self.dconv6 = DConvL(128, 64, 4, 2, 2)\n",
        "        self.dconv7 = DConvL(64, 3, 4, 2, 3)\n",
        "\n",
        "        # Convert to Neg residual\n",
        "        self.rem0 = ConvL(3, 3)\n",
        "        self.rem1 = ConvL(3, 3)\n",
        "        self.rem2 = nn.Sequential(nn.Conv2d(3,3, kernel_size=3,\n",
        "                                            stride=1, padding=1),\n",
        "                                  nn.Sigmoid())\n",
        "\n",
        "    def forward(self, x, att_map):\n",
        "        x0 = self.conv0(x)\n",
        "        x1 = self.conv1(x0)\n",
        "        x2 = self.conv2(x1)\n",
        "        x3 = self.conv3(x2)\n",
        "        x4 = self.conv4(x3)\n",
        "        x5 = self.conv5(x4)\n",
        "        x6 = self.conv6(x5)\n",
        "        x7 = self.conv7(x6)\n",
        "\n",
        "        xx = self.dconv0(x7)\n",
        "        xx += x6\n",
        "        xx = self.dconv1(xx)\n",
        "        xx += x5\n",
        "        xx = self.dconv2(xx)\n",
        "        xx += x4\n",
        "        xx = self.dconv3(xx)\n",
        "        xx += x3\n",
        "        xx = self.dconv4(xx)\n",
        "        xx += x2\n",
        "        xx = self.dconv5(xx)\n",
        "        xx += x1\n",
        "        xx = self.dconv6(xx)\n",
        "        xx += x0\n",
        "        xx = self.dconv7(xx)\n",
        "\n",
        "        xx = self.rem0(xx)\n",
        "        xx = self.rem1(xx)\n",
        "        xx = self.rem2(xx)\n",
        "\n",
        "        res = xx * att_map\n",
        "        out = res + x\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMEUx0Ylldei"
      },
      "source": [
        "# Generative Network\n",
        "class Gen(nn.Module):\n",
        "    def __init__(self, batch_size=None, step_num=None):\n",
        "        super(Gen, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.step = step_num\n",
        "        # Attention Detector\n",
        "        self.attL = []\n",
        "        self.remE = []\n",
        "        for i in range(self.step):\n",
        "          self.attL.append(AttDet())\n",
        "          self.remE.append(REncoder())\n",
        "        self.attL = nn.ModuleList(self.attL)\n",
        "        self.remE = nn.ModuleList(self.remE)\n",
        "        #        self.attL = AttDet()\n",
        "        # Convolutional LSTM cell\n",
        "        self.lstm = ConvLSTM(inp_dim=64, hid_dim=64)\n",
        "        # init hidden state\n",
        "        self.hidden = self.lstm.init_hidden(self.batch_size, (256,256))\n",
        "        # Attention Map\n",
        "        self.attM = nn.Sequential(\n",
        "                  nn.Conv2d(64, 1, kernel_size=3, stride=1, padding=1),\n",
        "                  nn.Sigmoid()\n",
        "        )\n",
        "        # Removal Encoder\n",
        "#        self.remE = REncoder()\n",
        "\n",
        "    def init_h(self):\n",
        "      self.hidden = self.lstm.init_hidden(self.batch_size, (256,256))\n",
        "\n",
        "    def forward(self, x):\n",
        "      in_batch = x.shape[0]\n",
        "      if in_batch != self.batch_size:\n",
        "        self.batch_size = in_batch\n",
        "      self.hidden = self.lstm.init_hidden(self.batch_size, (256,256))\n",
        "      with torch.autograd.set_detect_anomaly(True):\n",
        "        # attention map & output tensor\n",
        "        att_map = torch.empty(self.step, self.batch_size, 1, 256, 256).to(device)\n",
        "        out = torch.empty(self.step , self.batch_size, 3, 256, 256).to(device)\n",
        "        lstm_out = torch.zeros(self.batch_size, 64, 256, 256).to(device)\n",
        "        self.hidden = self.hidden.to(device)\n",
        "\n",
        "        # for N progressive steps\n",
        "        for i in range(self.step):\n",
        "            # attention detector\n",
        "            lstm_in = self.attL[i](x)\n",
        "            # LSTM Layer\n",
        "            lstm_out, self.hidden = self.lstm(lstm_in, lstm_out, self.hidden)\n",
        "            # Generate attention map\n",
        "            temp = self.attM(lstm_in)\n",
        "            # removal encoder\n",
        "            res = self.remE[i](x, temp)\n",
        "            # append to output\n",
        "            att_map[i] = temp\n",
        "            out[i] = res\n",
        "            x = res\n",
        "\n",
        "        # output to tensor\n",
        "#        att_map = torch.FloatTensor(att_map)\n",
        "#        out = torch.FloatTensor(out)\n",
        "\n",
        "        return att_map, out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FE38fMpfNqsh"
      },
      "source": [
        "# Discriminative Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wiOhoHzNr0t"
      },
      "source": [
        "# Discriminator\n",
        "class Disc(nn.Module):\n",
        "    def __init__(self, batch_size=None):\n",
        "        super(Disc, self).__init__()\n",
        "        self.batch_size = batch_size\n",
        "        self.conv0 = ConvL(3, 64, 4, 2, 1)\n",
        "        self.conv1 = ConvL(64, 128, 4, 2, 1)\n",
        "        self.conv2 = ConvL(128, 256, 4, 2, 1)\n",
        "        self.conv3 = ConvL(256, 512, 4, 2, 1)\n",
        "        self.conv4 = ConvL(512, 256, 4, 2, 1)\n",
        "        self.fc = nn.Sequential(nn.Linear(256*64, 1),\n",
        "                                nn.Sigmoid())\n",
        "\n",
        "    def forward(self, inp):\n",
        "      with torch.autograd.set_detect_anomaly(True):\n",
        "        self.batch_size = inp.shape[0]\n",
        "        x = self.conv0(inp)\n",
        "        x = self.conv1(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.conv4(x)\n",
        "        x = torch.flatten(x, 1)\n",
        "        out = self.fc(x)\n",
        "\n",
        "        return out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UXhORBrMmTFl"
      },
      "source": [
        "# Model Summary"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L-_ftVf9mWAn",
        "outputId": "8fbe0ba3-1526-41bb-bbec-51cd920867f0"
      },
      "source": [
        "# Generatior Model Summary\n",
        "from torchsummary import summary\n",
        "summary(gen_net, (3, 256, 256), device='cuda')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1          [-1, 8, 256, 256]             224\n",
            "       BatchNorm2d-2          [-1, 8, 256, 256]              16\n",
            "         LeakyReLU-3          [-1, 8, 256, 256]               0\n",
            "             ConvL-4          [-1, 8, 256, 256]               0\n",
            "            Conv2d-5          [-1, 8, 256, 256]             584\n",
            "       BatchNorm2d-6          [-1, 8, 256, 256]              16\n",
            "         LeakyReLU-7          [-1, 8, 256, 256]               0\n",
            "             ConvL-8          [-1, 8, 256, 256]               0\n",
            "            Conv2d-9         [-1, 16, 256, 256]           1,168\n",
            "      BatchNorm2d-10         [-1, 16, 256, 256]              32\n",
            "        LeakyReLU-11         [-1, 16, 256, 256]               0\n",
            "            ConvL-12         [-1, 16, 256, 256]               0\n",
            "           Conv2d-13         [-1, 16, 256, 256]           2,320\n",
            "      BatchNorm2d-14         [-1, 16, 256, 256]              32\n",
            "        LeakyReLU-15         [-1, 16, 256, 256]               0\n",
            "            ConvL-16         [-1, 16, 256, 256]               0\n",
            "           Conv2d-17         [-1, 16, 256, 256]           2,320\n",
            "      BatchNorm2d-18         [-1, 16, 256, 256]              32\n",
            "        LeakyReLU-19         [-1, 16, 256, 256]               0\n",
            "            ConvL-20         [-1, 16, 256, 256]               0\n",
            "           Conv2d-21         [-1, 32, 256, 256]           4,640\n",
            "      BatchNorm2d-22         [-1, 32, 256, 256]              64\n",
            "        LeakyReLU-23         [-1, 32, 256, 256]               0\n",
            "            ConvL-24         [-1, 32, 256, 256]               0\n",
            "           Conv2d-25         [-1, 32, 256, 256]           9,248\n",
            "      BatchNorm2d-26         [-1, 32, 256, 256]              64\n",
            "        LeakyReLU-27         [-1, 32, 256, 256]               0\n",
            "            ConvL-28         [-1, 32, 256, 256]               0\n",
            "           Conv2d-29         [-1, 64, 256, 256]          18,496\n",
            "      BatchNorm2d-30         [-1, 64, 256, 256]             128\n",
            "        LeakyReLU-31         [-1, 64, 256, 256]               0\n",
            "            ConvL-32         [-1, 64, 256, 256]               0\n",
            "           Conv2d-33         [-1, 64, 256, 256]          36,928\n",
            "      BatchNorm2d-34         [-1, 64, 256, 256]             128\n",
            "        LeakyReLU-35         [-1, 64, 256, 256]               0\n",
            "            ConvL-36         [-1, 64, 256, 256]               0\n",
            "           Conv2d-37         [-1, 64, 256, 256]          36,928\n",
            "      BatchNorm2d-38         [-1, 64, 256, 256]             128\n",
            "        LeakyReLU-39         [-1, 64, 256, 256]               0\n",
            "            ConvL-40         [-1, 64, 256, 256]               0\n",
            "           AttDet-41         [-1, 64, 256, 256]               0\n",
            "           Conv2d-42         [-1, 64, 256, 256]          73,792\n",
            "          Sigmoid-43         [-1, 64, 256, 256]               0\n",
            "           Conv2d-44         [-1, 64, 256, 256]          73,792\n",
            "          Sigmoid-45         [-1, 64, 256, 256]               0\n",
            "           Conv2d-46         [-1, 64, 256, 256]          73,792\n",
            "             Tanh-47         [-1, 64, 256, 256]               0\n",
            "           Conv2d-48         [-1, 64, 256, 256]          73,792\n",
            "          Sigmoid-49         [-1, 64, 256, 256]               0\n",
            "             Tanh-50         [-1, 64, 256, 256]               0\n",
            "         ConvLSTM-51  [[-1, 64, 256, 256], [-1, 64, 256, 256]]               0\n",
            "           Conv2d-52          [-1, 1, 256, 256]             577\n",
            "          Sigmoid-53          [-1, 1, 256, 256]               0\n",
            "           Conv2d-54         [-1, 64, 130, 130]           1,792\n",
            "      BatchNorm2d-55         [-1, 64, 130, 130]             128\n",
            "        LeakyReLU-56         [-1, 64, 130, 130]               0\n",
            "            ConvL-57         [-1, 64, 130, 130]               0\n",
            "           Conv2d-58          [-1, 128, 66, 66]          73,856\n",
            "      BatchNorm2d-59          [-1, 128, 66, 66]             256\n",
            "        LeakyReLU-60          [-1, 128, 66, 66]               0\n",
            "            ConvL-61          [-1, 128, 66, 66]               0\n",
            "           Conv2d-62          [-1, 256, 34, 34]         295,168\n",
            "      BatchNorm2d-63          [-1, 256, 34, 34]             512\n",
            "        LeakyReLU-64          [-1, 256, 34, 34]               0\n",
            "            ConvL-65          [-1, 256, 34, 34]               0\n",
            "           Conv2d-66          [-1, 512, 18, 18]       1,180,160\n",
            "      BatchNorm2d-67          [-1, 512, 18, 18]           1,024\n",
            "        LeakyReLU-68          [-1, 512, 18, 18]               0\n",
            "            ConvL-69          [-1, 512, 18, 18]               0\n",
            "           Conv2d-70          [-1, 512, 10, 10]       2,359,808\n",
            "      BatchNorm2d-71          [-1, 512, 10, 10]           1,024\n",
            "        LeakyReLU-72          [-1, 512, 10, 10]               0\n",
            "            ConvL-73          [-1, 512, 10, 10]               0\n",
            "           Conv2d-74            [-1, 512, 6, 6]       2,359,808\n",
            "      BatchNorm2d-75            [-1, 512, 6, 6]           1,024\n",
            "        LeakyReLU-76            [-1, 512, 6, 6]               0\n",
            "            ConvL-77            [-1, 512, 6, 6]               0\n",
            "           Conv2d-78            [-1, 512, 4, 4]       2,359,808\n",
            "      BatchNorm2d-79            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-80            [-1, 512, 4, 4]               0\n",
            "            ConvL-81            [-1, 512, 4, 4]               0\n",
            "           Conv2d-82            [-1, 512, 3, 3]       2,359,808\n",
            "      BatchNorm2d-83            [-1, 512, 3, 3]           1,024\n",
            "        LeakyReLU-84            [-1, 512, 3, 3]               0\n",
            "            ConvL-85            [-1, 512, 3, 3]               0\n",
            "  ConvTranspose2d-86            [-1, 512, 4, 4]       4,194,816\n",
            "      BatchNorm2d-87            [-1, 512, 4, 4]           1,024\n",
            "        LeakyReLU-88            [-1, 512, 4, 4]               0\n",
            "           DConvL-89            [-1, 512, 4, 4]               0\n",
            "  ConvTranspose2d-90            [-1, 512, 6, 6]       4,194,816\n",
            "      BatchNorm2d-91            [-1, 512, 6, 6]           1,024\n",
            "        LeakyReLU-92            [-1, 512, 6, 6]               0\n",
            "           DConvL-93            [-1, 512, 6, 6]               0\n",
            "  ConvTranspose2d-94          [-1, 512, 10, 10]       4,194,816\n",
            "      BatchNorm2d-95          [-1, 512, 10, 10]           1,024\n",
            "        LeakyReLU-96          [-1, 512, 10, 10]               0\n",
            "           DConvL-97          [-1, 512, 10, 10]               0\n",
            "  ConvTranspose2d-98          [-1, 512, 18, 18]       4,194,816\n",
            "      BatchNorm2d-99          [-1, 512, 18, 18]           1,024\n",
            "       LeakyReLU-100          [-1, 512, 18, 18]               0\n",
            "          DConvL-101          [-1, 512, 18, 18]               0\n",
            " ConvTranspose2d-102          [-1, 256, 34, 34]       2,097,408\n",
            "     BatchNorm2d-103          [-1, 256, 34, 34]             512\n",
            "       LeakyReLU-104          [-1, 256, 34, 34]               0\n",
            "          DConvL-105          [-1, 256, 34, 34]               0\n",
            " ConvTranspose2d-106          [-1, 128, 66, 66]         524,416\n",
            "     BatchNorm2d-107          [-1, 128, 66, 66]             256\n",
            "       LeakyReLU-108          [-1, 128, 66, 66]               0\n",
            "          DConvL-109          [-1, 128, 66, 66]               0\n",
            " ConvTranspose2d-110         [-1, 64, 130, 130]         131,136\n",
            "     BatchNorm2d-111         [-1, 64, 130, 130]             128\n",
            "       LeakyReLU-112         [-1, 64, 130, 130]               0\n",
            "          DConvL-113         [-1, 64, 130, 130]               0\n",
            " ConvTranspose2d-114          [-1, 3, 256, 256]           3,075\n",
            "     BatchNorm2d-115          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-116          [-1, 3, 256, 256]               0\n",
            "          DConvL-117          [-1, 3, 256, 256]               0\n",
            "          Conv2d-118          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-119          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-120          [-1, 3, 256, 256]               0\n",
            "           ConvL-121          [-1, 3, 256, 256]               0\n",
            "          Conv2d-122          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-123          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-124          [-1, 3, 256, 256]               0\n",
            "           ConvL-125          [-1, 3, 256, 256]               0\n",
            "          Conv2d-126          [-1, 3, 256, 256]              84\n",
            "         Sigmoid-127          [-1, 3, 256, 256]               0\n",
            "        REncoder-128          [-1, 3, 256, 256]               0\n",
            "          Conv2d-129          [-1, 8, 256, 256]             224\n",
            "     BatchNorm2d-130          [-1, 8, 256, 256]              16\n",
            "       LeakyReLU-131          [-1, 8, 256, 256]               0\n",
            "           ConvL-132          [-1, 8, 256, 256]               0\n",
            "          Conv2d-133          [-1, 8, 256, 256]             584\n",
            "     BatchNorm2d-134          [-1, 8, 256, 256]              16\n",
            "       LeakyReLU-135          [-1, 8, 256, 256]               0\n",
            "           ConvL-136          [-1, 8, 256, 256]               0\n",
            "          Conv2d-137         [-1, 16, 256, 256]           1,168\n",
            "     BatchNorm2d-138         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-139         [-1, 16, 256, 256]               0\n",
            "           ConvL-140         [-1, 16, 256, 256]               0\n",
            "          Conv2d-141         [-1, 16, 256, 256]           2,320\n",
            "     BatchNorm2d-142         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-143         [-1, 16, 256, 256]               0\n",
            "           ConvL-144         [-1, 16, 256, 256]               0\n",
            "          Conv2d-145         [-1, 16, 256, 256]           2,320\n",
            "     BatchNorm2d-146         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-147         [-1, 16, 256, 256]               0\n",
            "           ConvL-148         [-1, 16, 256, 256]               0\n",
            "          Conv2d-149         [-1, 32, 256, 256]           4,640\n",
            "     BatchNorm2d-150         [-1, 32, 256, 256]              64\n",
            "       LeakyReLU-151         [-1, 32, 256, 256]               0\n",
            "           ConvL-152         [-1, 32, 256, 256]               0\n",
            "          Conv2d-153         [-1, 32, 256, 256]           9,248\n",
            "     BatchNorm2d-154         [-1, 32, 256, 256]              64\n",
            "       LeakyReLU-155         [-1, 32, 256, 256]               0\n",
            "           ConvL-156         [-1, 32, 256, 256]               0\n",
            "          Conv2d-157         [-1, 64, 256, 256]          18,496\n",
            "     BatchNorm2d-158         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-159         [-1, 64, 256, 256]               0\n",
            "           ConvL-160         [-1, 64, 256, 256]               0\n",
            "          Conv2d-161         [-1, 64, 256, 256]          36,928\n",
            "     BatchNorm2d-162         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-163         [-1, 64, 256, 256]               0\n",
            "           ConvL-164         [-1, 64, 256, 256]               0\n",
            "          Conv2d-165         [-1, 64, 256, 256]          36,928\n",
            "     BatchNorm2d-166         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-167         [-1, 64, 256, 256]               0\n",
            "           ConvL-168         [-1, 64, 256, 256]               0\n",
            "          AttDet-169         [-1, 64, 256, 256]               0\n",
            "          Conv2d-170         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-171         [-1, 64, 256, 256]               0\n",
            "          Conv2d-172         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-173         [-1, 64, 256, 256]               0\n",
            "          Conv2d-174         [-1, 64, 256, 256]          73,792\n",
            "            Tanh-175         [-1, 64, 256, 256]               0\n",
            "          Conv2d-176         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-177         [-1, 64, 256, 256]               0\n",
            "            Tanh-178         [-1, 64, 256, 256]               0\n",
            "        ConvLSTM-179  [[-1, 64, 256, 256], [-1, 64, 256, 256]]               0\n",
            "          Conv2d-180          [-1, 1, 256, 256]             577\n",
            "         Sigmoid-181          [-1, 1, 256, 256]               0\n",
            "          Conv2d-182         [-1, 64, 130, 130]           1,792\n",
            "     BatchNorm2d-183         [-1, 64, 130, 130]             128\n",
            "       LeakyReLU-184         [-1, 64, 130, 130]               0\n",
            "           ConvL-185         [-1, 64, 130, 130]               0\n",
            "          Conv2d-186          [-1, 128, 66, 66]          73,856\n",
            "     BatchNorm2d-187          [-1, 128, 66, 66]             256\n",
            "       LeakyReLU-188          [-1, 128, 66, 66]               0\n",
            "           ConvL-189          [-1, 128, 66, 66]               0\n",
            "          Conv2d-190          [-1, 256, 34, 34]         295,168\n",
            "     BatchNorm2d-191          [-1, 256, 34, 34]             512\n",
            "       LeakyReLU-192          [-1, 256, 34, 34]               0\n",
            "           ConvL-193          [-1, 256, 34, 34]               0\n",
            "          Conv2d-194          [-1, 512, 18, 18]       1,180,160\n",
            "     BatchNorm2d-195          [-1, 512, 18, 18]           1,024\n",
            "       LeakyReLU-196          [-1, 512, 18, 18]               0\n",
            "           ConvL-197          [-1, 512, 18, 18]               0\n",
            "          Conv2d-198          [-1, 512, 10, 10]       2,359,808\n",
            "     BatchNorm2d-199          [-1, 512, 10, 10]           1,024\n",
            "       LeakyReLU-200          [-1, 512, 10, 10]               0\n",
            "           ConvL-201          [-1, 512, 10, 10]               0\n",
            "          Conv2d-202            [-1, 512, 6, 6]       2,359,808\n",
            "     BatchNorm2d-203            [-1, 512, 6, 6]           1,024\n",
            "       LeakyReLU-204            [-1, 512, 6, 6]               0\n",
            "           ConvL-205            [-1, 512, 6, 6]               0\n",
            "          Conv2d-206            [-1, 512, 4, 4]       2,359,808\n",
            "     BatchNorm2d-207            [-1, 512, 4, 4]           1,024\n",
            "       LeakyReLU-208            [-1, 512, 4, 4]               0\n",
            "           ConvL-209            [-1, 512, 4, 4]               0\n",
            "          Conv2d-210            [-1, 512, 3, 3]       2,359,808\n",
            "     BatchNorm2d-211            [-1, 512, 3, 3]           1,024\n",
            "       LeakyReLU-212            [-1, 512, 3, 3]               0\n",
            "           ConvL-213            [-1, 512, 3, 3]               0\n",
            " ConvTranspose2d-214            [-1, 512, 4, 4]       4,194,816\n",
            "     BatchNorm2d-215            [-1, 512, 4, 4]           1,024\n",
            "       LeakyReLU-216            [-1, 512, 4, 4]               0\n",
            "          DConvL-217            [-1, 512, 4, 4]               0\n",
            " ConvTranspose2d-218            [-1, 512, 6, 6]       4,194,816\n",
            "     BatchNorm2d-219            [-1, 512, 6, 6]           1,024\n",
            "       LeakyReLU-220            [-1, 512, 6, 6]               0\n",
            "          DConvL-221            [-1, 512, 6, 6]               0\n",
            " ConvTranspose2d-222          [-1, 512, 10, 10]       4,194,816\n",
            "     BatchNorm2d-223          [-1, 512, 10, 10]           1,024\n",
            "       LeakyReLU-224          [-1, 512, 10, 10]               0\n",
            "          DConvL-225          [-1, 512, 10, 10]               0\n",
            " ConvTranspose2d-226          [-1, 512, 18, 18]       4,194,816\n",
            "     BatchNorm2d-227          [-1, 512, 18, 18]           1,024\n",
            "       LeakyReLU-228          [-1, 512, 18, 18]               0\n",
            "          DConvL-229          [-1, 512, 18, 18]               0\n",
            " ConvTranspose2d-230          [-1, 256, 34, 34]       2,097,408\n",
            "     BatchNorm2d-231          [-1, 256, 34, 34]             512\n",
            "       LeakyReLU-232          [-1, 256, 34, 34]               0\n",
            "          DConvL-233          [-1, 256, 34, 34]               0\n",
            " ConvTranspose2d-234          [-1, 128, 66, 66]         524,416\n",
            "     BatchNorm2d-235          [-1, 128, 66, 66]             256\n",
            "       LeakyReLU-236          [-1, 128, 66, 66]               0\n",
            "          DConvL-237          [-1, 128, 66, 66]               0\n",
            " ConvTranspose2d-238         [-1, 64, 130, 130]         131,136\n",
            "     BatchNorm2d-239         [-1, 64, 130, 130]             128\n",
            "       LeakyReLU-240         [-1, 64, 130, 130]               0\n",
            "          DConvL-241         [-1, 64, 130, 130]               0\n",
            " ConvTranspose2d-242          [-1, 3, 256, 256]           3,075\n",
            "     BatchNorm2d-243          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-244          [-1, 3, 256, 256]               0\n",
            "          DConvL-245          [-1, 3, 256, 256]               0\n",
            "          Conv2d-246          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-247          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-248          [-1, 3, 256, 256]               0\n",
            "           ConvL-249          [-1, 3, 256, 256]               0\n",
            "          Conv2d-250          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-251          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-252          [-1, 3, 256, 256]               0\n",
            "           ConvL-253          [-1, 3, 256, 256]               0\n",
            "          Conv2d-254          [-1, 3, 256, 256]              84\n",
            "         Sigmoid-255          [-1, 3, 256, 256]               0\n",
            "        REncoder-256          [-1, 3, 256, 256]               0\n",
            "          Conv2d-257          [-1, 8, 256, 256]             224\n",
            "     BatchNorm2d-258          [-1, 8, 256, 256]              16\n",
            "       LeakyReLU-259          [-1, 8, 256, 256]               0\n",
            "           ConvL-260          [-1, 8, 256, 256]               0\n",
            "          Conv2d-261          [-1, 8, 256, 256]             584\n",
            "     BatchNorm2d-262          [-1, 8, 256, 256]              16\n",
            "       LeakyReLU-263          [-1, 8, 256, 256]               0\n",
            "           ConvL-264          [-1, 8, 256, 256]               0\n",
            "          Conv2d-265         [-1, 16, 256, 256]           1,168\n",
            "     BatchNorm2d-266         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-267         [-1, 16, 256, 256]               0\n",
            "           ConvL-268         [-1, 16, 256, 256]               0\n",
            "          Conv2d-269         [-1, 16, 256, 256]           2,320\n",
            "     BatchNorm2d-270         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-271         [-1, 16, 256, 256]               0\n",
            "           ConvL-272         [-1, 16, 256, 256]               0\n",
            "          Conv2d-273         [-1, 16, 256, 256]           2,320\n",
            "     BatchNorm2d-274         [-1, 16, 256, 256]              32\n",
            "       LeakyReLU-275         [-1, 16, 256, 256]               0\n",
            "           ConvL-276         [-1, 16, 256, 256]               0\n",
            "          Conv2d-277         [-1, 32, 256, 256]           4,640\n",
            "     BatchNorm2d-278         [-1, 32, 256, 256]              64\n",
            "       LeakyReLU-279         [-1, 32, 256, 256]               0\n",
            "           ConvL-280         [-1, 32, 256, 256]               0\n",
            "          Conv2d-281         [-1, 32, 256, 256]           9,248\n",
            "     BatchNorm2d-282         [-1, 32, 256, 256]              64\n",
            "       LeakyReLU-283         [-1, 32, 256, 256]               0\n",
            "           ConvL-284         [-1, 32, 256, 256]               0\n",
            "          Conv2d-285         [-1, 64, 256, 256]          18,496\n",
            "     BatchNorm2d-286         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-287         [-1, 64, 256, 256]               0\n",
            "           ConvL-288         [-1, 64, 256, 256]               0\n",
            "          Conv2d-289         [-1, 64, 256, 256]          36,928\n",
            "     BatchNorm2d-290         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-291         [-1, 64, 256, 256]               0\n",
            "           ConvL-292         [-1, 64, 256, 256]               0\n",
            "          Conv2d-293         [-1, 64, 256, 256]          36,928\n",
            "     BatchNorm2d-294         [-1, 64, 256, 256]             128\n",
            "       LeakyReLU-295         [-1, 64, 256, 256]               0\n",
            "           ConvL-296         [-1, 64, 256, 256]               0\n",
            "          AttDet-297         [-1, 64, 256, 256]               0\n",
            "          Conv2d-298         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-299         [-1, 64, 256, 256]               0\n",
            "          Conv2d-300         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-301         [-1, 64, 256, 256]               0\n",
            "          Conv2d-302         [-1, 64, 256, 256]          73,792\n",
            "            Tanh-303         [-1, 64, 256, 256]               0\n",
            "          Conv2d-304         [-1, 64, 256, 256]          73,792\n",
            "         Sigmoid-305         [-1, 64, 256, 256]               0\n",
            "            Tanh-306         [-1, 64, 256, 256]               0\n",
            "        ConvLSTM-307  [[-1, 64, 256, 256], [-1, 64, 256, 256]]               0\n",
            "          Conv2d-308          [-1, 1, 256, 256]             577\n",
            "         Sigmoid-309          [-1, 1, 256, 256]               0\n",
            "          Conv2d-310         [-1, 64, 130, 130]           1,792\n",
            "     BatchNorm2d-311         [-1, 64, 130, 130]             128\n",
            "       LeakyReLU-312         [-1, 64, 130, 130]               0\n",
            "           ConvL-313         [-1, 64, 130, 130]               0\n",
            "          Conv2d-314          [-1, 128, 66, 66]          73,856\n",
            "     BatchNorm2d-315          [-1, 128, 66, 66]             256\n",
            "       LeakyReLU-316          [-1, 128, 66, 66]               0\n",
            "           ConvL-317          [-1, 128, 66, 66]               0\n",
            "          Conv2d-318          [-1, 256, 34, 34]         295,168\n",
            "     BatchNorm2d-319          [-1, 256, 34, 34]             512\n",
            "       LeakyReLU-320          [-1, 256, 34, 34]               0\n",
            "           ConvL-321          [-1, 256, 34, 34]               0\n",
            "          Conv2d-322          [-1, 512, 18, 18]       1,180,160\n",
            "     BatchNorm2d-323          [-1, 512, 18, 18]           1,024\n",
            "       LeakyReLU-324          [-1, 512, 18, 18]               0\n",
            "           ConvL-325          [-1, 512, 18, 18]               0\n",
            "          Conv2d-326          [-1, 512, 10, 10]       2,359,808\n",
            "     BatchNorm2d-327          [-1, 512, 10, 10]           1,024\n",
            "       LeakyReLU-328          [-1, 512, 10, 10]               0\n",
            "           ConvL-329          [-1, 512, 10, 10]               0\n",
            "          Conv2d-330            [-1, 512, 6, 6]       2,359,808\n",
            "     BatchNorm2d-331            [-1, 512, 6, 6]           1,024\n",
            "       LeakyReLU-332            [-1, 512, 6, 6]               0\n",
            "           ConvL-333            [-1, 512, 6, 6]               0\n",
            "          Conv2d-334            [-1, 512, 4, 4]       2,359,808\n",
            "     BatchNorm2d-335            [-1, 512, 4, 4]           1,024\n",
            "       LeakyReLU-336            [-1, 512, 4, 4]               0\n",
            "           ConvL-337            [-1, 512, 4, 4]               0\n",
            "          Conv2d-338            [-1, 512, 3, 3]       2,359,808\n",
            "     BatchNorm2d-339            [-1, 512, 3, 3]           1,024\n",
            "       LeakyReLU-340            [-1, 512, 3, 3]               0\n",
            "           ConvL-341            [-1, 512, 3, 3]               0\n",
            " ConvTranspose2d-342            [-1, 512, 4, 4]       4,194,816\n",
            "     BatchNorm2d-343            [-1, 512, 4, 4]           1,024\n",
            "       LeakyReLU-344            [-1, 512, 4, 4]               0\n",
            "          DConvL-345            [-1, 512, 4, 4]               0\n",
            " ConvTranspose2d-346            [-1, 512, 6, 6]       4,194,816\n",
            "     BatchNorm2d-347            [-1, 512, 6, 6]           1,024\n",
            "       LeakyReLU-348            [-1, 512, 6, 6]               0\n",
            "          DConvL-349            [-1, 512, 6, 6]               0\n",
            " ConvTranspose2d-350          [-1, 512, 10, 10]       4,194,816\n",
            "     BatchNorm2d-351          [-1, 512, 10, 10]           1,024\n",
            "       LeakyReLU-352          [-1, 512, 10, 10]               0\n",
            "          DConvL-353          [-1, 512, 10, 10]               0\n",
            " ConvTranspose2d-354          [-1, 512, 18, 18]       4,194,816\n",
            "     BatchNorm2d-355          [-1, 512, 18, 18]           1,024\n",
            "       LeakyReLU-356          [-1, 512, 18, 18]               0\n",
            "          DConvL-357          [-1, 512, 18, 18]               0\n",
            " ConvTranspose2d-358          [-1, 256, 34, 34]       2,097,408\n",
            "     BatchNorm2d-359          [-1, 256, 34, 34]             512\n",
            "       LeakyReLU-360          [-1, 256, 34, 34]               0\n",
            "          DConvL-361          [-1, 256, 34, 34]               0\n",
            " ConvTranspose2d-362          [-1, 128, 66, 66]         524,416\n",
            "     BatchNorm2d-363          [-1, 128, 66, 66]             256\n",
            "       LeakyReLU-364          [-1, 128, 66, 66]               0\n",
            "          DConvL-365          [-1, 128, 66, 66]               0\n",
            " ConvTranspose2d-366         [-1, 64, 130, 130]         131,136\n",
            "     BatchNorm2d-367         [-1, 64, 130, 130]             128\n",
            "       LeakyReLU-368         [-1, 64, 130, 130]               0\n",
            "          DConvL-369         [-1, 64, 130, 130]               0\n",
            " ConvTranspose2d-370          [-1, 3, 256, 256]           3,075\n",
            "     BatchNorm2d-371          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-372          [-1, 3, 256, 256]               0\n",
            "          DConvL-373          [-1, 3, 256, 256]               0\n",
            "          Conv2d-374          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-375          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-376          [-1, 3, 256, 256]               0\n",
            "           ConvL-377          [-1, 3, 256, 256]               0\n",
            "          Conv2d-378          [-1, 3, 256, 256]              84\n",
            "     BatchNorm2d-379          [-1, 3, 256, 256]               6\n",
            "       LeakyReLU-380          [-1, 3, 256, 256]               0\n",
            "           ConvL-381          [-1, 3, 256, 256]               0\n",
            "          Conv2d-382          [-1, 3, 256, 256]              84\n",
            "         Sigmoid-383          [-1, 3, 256, 256]               0\n",
            "        REncoder-384          [-1, 3, 256, 256]               0\n",
            "================================================================\n",
            "Total params: 92,838,078\n",
            "Trainable params: 92,838,078\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.75\n",
            "Forward/backward pass size (MB): 402649834.12\n",
            "Params size (MB): 354.15\n",
            "Estimated Total Size (MB): 402650189.02\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9kMHVY_DgDY"
      },
      "source": [
        "# Discriminator Model Summary\n",
        "from torchsummary import summary\n",
        "summary(dis_net, (3, 128, 128), device='cpu')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xi0LpF1lNoDR"
      },
      "source": [
        "# Training Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wGpFDZKtMD3y"
      },
      "source": [
        "# Perceptual loss by VGG16\n",
        "class VGGPerceptualLoss(torch.nn.Module):\n",
        "    def __init__(self, resize=True):\n",
        "        super(VGGPerceptualLoss, self).__init__()\n",
        "        blocks = []\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[:4].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[4:9].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[9:16].eval())\n",
        "        blocks.append(torchvision.models.vgg16(pretrained=True).features[16:23].eval())\n",
        "        for bl in blocks:\n",
        "            for p in bl:\n",
        "                p.requires_grad = False\n",
        "        self.blocks = torch.nn.ModuleList(blocks)\n",
        "        self.transform = torch.nn.functional.interpolate\n",
        "        self.mean = torch.nn.Parameter(torch.tensor([0.485, 0.456, 0.406]).view(1,3,1,1))\n",
        "        self.std = torch.nn.Parameter(torch.tensor([0.229, 0.224, 0.225]).view(1,3,1,1))\n",
        "        self.resize = resize\n",
        "\n",
        "    def forward(self, input, target):\n",
        "        if input.shape[1] != 3:\n",
        "            input = input.repeat(1, 3, 1, 1)\n",
        "            target = target.repeat(1, 3, 1, 1)\n",
        "        input = (input-self.mean) / self.std\n",
        "        target = (target-self.mean) / self.std\n",
        "        if self.resize:\n",
        "            input = self.transform(input, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "            target = self.transform(target, mode='bilinear', size=(224, 224), align_corners=False)\n",
        "        loss = 0.0\n",
        "        x = input\n",
        "        y = target\n",
        "        for block in self.blocks:\n",
        "            x = block(x)\n",
        "            y = block(y)\n",
        "            loss += torch.nn.functional.mse_loss(x, y)\n",
        "        return loss"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "40yx2QjTMJse",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 85,
          "referenced_widgets": [
            "355b033cde6d493681decd1a462f98ef",
            "98c8c77e1344429891d580400f9f9c97",
            "2ec99806c2664785ae17c03a1f09f6c6",
            "b4c55f5066fe49c68985304fbd5f83d8",
            "2dae5b2882be4a6ebec5910a76051956",
            "b418f88ca5284787a9ffd91b6b8885cb",
            "a631f4df5e5749d4b0a162aae387a406",
            "2a3ea0e9fc104d569b3564626d86e4f7"
          ]
        },
        "outputId": "17ce1595-78bc-4514-8e8d-03a1a9c6f208"
      },
      "source": [
        "# learning parameters\n",
        "steps = 3   # Number of progressive step\n",
        "beta = 0.7  # weight for MSE step\n",
        "lamb = 0.7  # weight for Semi-Supervised learning\n",
        "l_rate_g = 0.0002\n",
        "#l_rate_d = 0.0002\n",
        "\n",
        "gen_net = Gen(batch_size=batch_num, step_num=steps)\n",
        "#dis_net = Disc(batch_size=batch_num)\n",
        "\n",
        "# learning loss\n",
        "MSE = nn.MSELoss()    # Mean Square Error\n",
        "VGG = VGGPerceptualLoss(resize=True).to(device)\n",
        "ADV = nn.BCELoss()    # Adversarial Loss : Binary CE\n",
        "\n",
        "# optimizer\n",
        "gen_optim = torch.optim.SGD(gen_net.parameters(), lr=l_rate_g, momentum=0.9)\n",
        "#dis_optim = torch.optim.Adam(dis_net.parameters(), lr=l_rate_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "355b033cde6d493681decd1a462f98ef",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=553433881.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 484
        },
        "id": "A7KxisKTsHwS",
        "outputId": "d59ee2cd-334d-4240-ab0b-34f0fe588847"
      },
      "source": [
        "# Load model params\n",
        "PATH = '/content/drive/My Drive/KU/4/'\n",
        "SAVE_PATH = PATH + 'ARGAN_BN/'\n",
        "gen_PATH = PATH + 'ARGAN256_gen_temp.pth'\n",
        "#dis_PATH = PATH + 'ARGAN256_dis_temp.pth'\n",
        "\n",
        "\n",
        "trained = 0\n",
        "if os.path.isfile(gen_PATH):\n",
        "  gen_net.load_state_dict(torch.load(gen_PATH))\n",
        "  trained = 0\n",
        "\"\"\"\n",
        "if os.path.isfile(dis_PATH):\n",
        "  dis_net.load_state_dict(torch.load(dis_PATH))\n",
        "  trained = 0\n",
        "\"\"\"\n",
        "if torch.cuda.is_available:\n",
        "  print('CUDA available')\n",
        "  device = \"cuda:0\"\n",
        "gen_net.train()\n",
        "#dis_net.train()\n",
        "\n",
        "for epoch in range(10):\n",
        "#    print('======================[%d epoch] running====================='\n",
        "#          %(epoch+trained+1))\n",
        "\n",
        "    # loss per epoch\n",
        "    det_loss = 0.0\n",
        "    rem_loss = 0.0\n",
        "    adv_loss = 0.0\n",
        "\n",
        "    for i, datas in enumerate(trainloader):\n",
        "\n",
        "        det_err = 0.0\n",
        "        rem_err = 0.0\n",
        "\n",
        "        # from dataset\n",
        "        image, matte, free = datas\n",
        "        image = image.to(device)\n",
        "        matte = matte.to(device)\n",
        "        free = free.to(device)\n",
        "        if torch.cuda.is_available:\n",
        "          gen_net.cuda()\n",
        "\n",
        "        # Generator Output\n",
        "        mattes, frees = gen_net(image)\n",
        "\n",
        "        with torch.autograd.set_detect_anomaly(True):\n",
        "              \"\"\"\n",
        "              # train Discriminative Net\n",
        "              dis_optim.zero_grad()\n",
        "              # real data Error\n",
        "              real_out = dis_net(free)\n",
        "              real_label = torch.ones(free.shape[0],1).to(device)\n",
        "              real_err = ADV(real_out, real_label)\n",
        "              real_err.backward()\n",
        "              # fake data Error\n",
        "              fake_out = dis_net(frees[steps-1].detach())\n",
        "              fake_label = torch.zeros(frees[steps-1].shape[0], 1).to(device)\n",
        "              fake_err = ADV(fake_out, fake_label)\n",
        "              fake_err.backward()\n",
        "\n",
        "              dis_err = real_err + fake_err\n",
        "              dis_optim.step()\n",
        "\n",
        "#              real_loss += real_err\n",
        "#              fake_loss += fake_err\n",
        "              \"\"\"\n",
        "\n",
        "              # train Generative Network\n",
        "              gen_optim.zero_grad()\n",
        "              # for N steps\n",
        "              for n in range(steps):\n",
        "                  # detector loss : MSE\n",
        "                  det_err += pow(beta, steps-n) * MSE(matte, mattes[n])\n",
        "                  # removal loss : acc loss + perceptual loss\n",
        "                  rem_err += pow(beta, steps-n) * MSE(free, frees[n])\n",
        "                  rem_err += VGG(free, frees[n]) / 10\n",
        "\n",
        "              # Adversarial loss\n",
        "#              out = dis_net(frees[steps-1])\n",
        "              #adv_err = ADV(out, real_label)\n",
        "\n",
        "              total_loss = det_err + rem_err\n",
        "              total_loss.backward()\n",
        "              gen_optim.step()\n",
        "\n",
        "              # loss per epoch\n",
        "              det_loss += det_err\n",
        "              rem_loss += rem_err\n",
        "              #adv_loss += adv_err\n",
        "\n",
        "              \"\"\" SAVE every batch\n",
        "              img_fname = temp_path + str(i+1) + \"_img.jpg\"\n",
        "              matt_fname = temp_path + str(i+1) + '_matt.jpg'\n",
        "              fre_fname = temp_path + str(i+1) + '_free.jpg'\n",
        "\n",
        "              img_out = image.cpu()\n",
        "              save_batch(img_out, dprow, img_fname)\n",
        "              matt_out = mattes[steps-1].cpu()\n",
        "              save_batch(matt_out, dprow, matt_fname)\n",
        "              free_out = frees[steps-1].cpu()\n",
        "              save_batch(free_out, dprow, fre_fname)\n",
        "              \"\"\"\n",
        "\n",
        "    # 1 epoch finished\n",
        "    total = det_loss + rem_loss + adv_loss\n",
        "    print('[%d epoch]\\t det : %f, rem : %f, adv : %f, total : %f'\n",
        "            %(epoch+trained+1, det_loss, rem_loss, adv_loss, total))\n",
        "#    print('\\t\\t total loss = %f' %(det_loss + rem_loss + adv_loss))\n",
        "    torch.save(gen_net.state_dict(), gen_PATH)\n",
        "#    torch.save(dis_net.state_dict(), dis_PATH)\n",
        "\n",
        "    img_fname = SAVE_PATH + str(epoch+trained+1) + \"_img.jpg\"\n",
        "    mat_fname = SAVE_PATH + str(epoch+trained+1) + \"_matt.jpg\"\n",
        "    fre_fname = SAVE_PATH + str(epoch+trained+1) + \"_free.jpg\"\n",
        "\n",
        "    # data out : to 'cpu'\n",
        "    img_out = image.cpu()\n",
        "    save_batch(img_out, dprow, img_fname)\n",
        "    matt_out = mattes[steps-1].cpu()\n",
        "    save_batch(matt_out, dprow, mat_fname)\n",
        "    free_out = frees[steps-1].cpu()\n",
        "    save_batch(free_out, dprow, fre_fname)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "CUDA available\n",
            "[1 epoch]\t det : 93.487061, rem : 305.857819, adv : 0.000000, total : 399.344879\n",
            "[2 epoch]\t det : 90.005196, rem : 266.892517, adv : 0.000000, total : 356.897705\n",
            "[3 epoch]\t det : 85.225288, rem : 262.741516, adv : 0.000000, total : 347.966797\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-9e655a11f601>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m               \u001b[0mtotal_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdet_err\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mrem_err\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m               \u001b[0mtotal_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m               \u001b[0mgen_optim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    145\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    146\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 147\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    148\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XM3wr55kn5AJ"
      },
      "source": [
        "7M for 1 epoch"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jje4gutYRWSf"
      },
      "source": [
        "# Test Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yd7AOytJ1WJC"
      },
      "source": [
        "# Model parameters\n",
        "steps = 3   # Number of progressive step\n",
        "\n",
        "gen_net = Gen(batch_size=batch_num, step_num=steps)\n",
        "#dis_net = Disc(batch_size=batch_num)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MiwliWIw3Ohw"
      },
      "source": [
        "Metrics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "66YYdGuruipb"
      },
      "source": [
        "# Balanced Error Rate\n",
        "class BERScore(nn.Module):\n",
        "  def __init__(self, thresh=None):\n",
        "    super().__init__()\n",
        "    self.thr = thresh\n",
        "\n",
        "  def forward(self, est, gt):\n",
        "    est_b = (est>self.thr).float()\n",
        "\n",
        "    conf_mat = est_b / gt\n",
        "\n",
        "    tp = torch.sum(conf_mat == 1).item()\n",
        "    fp = torch.sum(conf_mat == float('inf')).item()\n",
        "    tn = torch.sum(torch.isnan(conf_mat)).item()\n",
        "    fn = torch.sum(conf_mat == 0).item()\n",
        "\n",
        "    sensit = tp / (tp+fn)\n",
        "    specif = tn / (tn+fp)\n",
        "    return (1 - (sensit + specif)/2 )\n",
        "\n",
        "# Balanced Error Rate & sensitivity & specificity\n",
        "class BERScores(nn.Module):\n",
        "  def __init__(self, thresh=None):\n",
        "    super().__init__()\n",
        "    self.thr = thresh\n",
        "\n",
        "  def forward(self, est, gt):\n",
        "    est_b = (est>self.thr).float()\n",
        "\n",
        "    conf_mat = est_b / gt\n",
        "\n",
        "    tp = torch.sum(conf_mat == 1).item()\n",
        "    fp = torch.sum(conf_mat == float('inf')).item()\n",
        "    tn = torch.sum(torch.isnan(conf_mat)).item()\n",
        "    fn = torch.sum(conf_mat == 0).item()\n",
        "\n",
        "    sensit = tp / (tp+fn)\n",
        "    specif = tn / (tn+fp)\n",
        "    return sensit, specif, (1 - (sensit + specif)/2 )\n",
        "\n",
        "# Root Mean Square\n",
        "class RMSEScore(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.mse = nn.MSELoss()\n",
        "\n",
        "  def forward(self, est, gt):\n",
        "    score = torch.sqrt(self.mse(est, gt))\n",
        "    return float(score)\n",
        "\n",
        "BER = BERScore(thresh=0.5)\n",
        "BERs = BERScores(thresh=0.5)\n",
        "RMSE = RMSEScore()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XKdRsT32WELK"
      },
      "source": [
        "# image transforms\n",
        "def rgb2lab(image):\n",
        "  temp = image.cpu()\n",
        "  out = torch.empty_like(temp)\n",
        "  temp = np.transpose(temp, (0,2,3,1))\n",
        "  for i in range(temp.shape[0]):\n",
        "    out[i] = torch.FloatTensor(np.transpose(color.rgb2lab(np.array(temp[i])),\n",
        "                                          (2,0,1)))\n",
        "  out = out.to(device)\n",
        "  return out\n",
        "\n",
        "matt2src = transforms.Compose([\n",
        "                               transforms.Resize(size=(480,640)),\n",
        "])\n",
        "free2src = transforms.Compose([\n",
        "                               transforms.Resize(size=(480,640)),\n",
        "                               transforms.Lambda(rgb2lab)\n",
        "])\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R6BCWyo9RT0M"
      },
      "source": [
        "Network Evaluation with batch_size 4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FZm_G-Du3TKd",
        "outputId": "26d2d510-2471-48f2-8568-f8843a18c08f"
      },
      "source": [
        "# Generate Testset Output\n",
        "if torch.cuda.is_available:\n",
        "#  torch.cuda.empty_cache()\n",
        "#  dis_net.cuda()\n",
        "  gen_net.cuda()\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "gen_net.eval()\n",
        "#dis_net.eval()\n",
        "for m in gen_net.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        m.track_running_stats = False\n",
        "\n",
        "PATH = '/content/drive/My Drive/KU/4/'\n",
        "gen_PATH = PATH + 'ARGAN256_gen_BN.pth'\n",
        "#dis_PATH = PATH + 'ARGAN256_dis_net.pth'\n",
        "SAVE_PATH = PATH + 'ARGAN256_test/zzz/'\n",
        "\n",
        "if os.path.isfile(gen_PATH):\n",
        "#  gen_net.load_state_dict(torch.load(gen_PATH, map_location=device))\n",
        "  gen_net.load_state_dict(torch.load(gen_PATH))\n",
        "else:\n",
        "  print(\"No trained Gen Net\")\n",
        "\"\"\"\n",
        "if os.path.isfile(dis_PATH):\n",
        "  dis_net.load_state_dict(torch.load(dis_PATH, map_location=device))\n",
        "else:\n",
        "  print(\"No trained Disc Net\")\n",
        "\"\"\"\n",
        "total_BER = []\n",
        "total_RMSE = []\n",
        "total_SRMSE = []\n",
        "\n",
        "for i, datas in enumerate(testloader):\n",
        "  with torch.no_grad():\n",
        "    image, matte, free, src_matte, src_free = datas\n",
        "    image = image.to(device)\n",
        "    matte = matte.to(device)\n",
        "    free = free.to(device)\n",
        "    src_matte = src_matte.to(device)\n",
        "    src_free = src_free.to(device)\n",
        "\n",
        "    mattes, frees = gen_net(image)\n",
        "\n",
        "    image_ = matt2src(image)\n",
        "    mattes_ = matt2src(mattes[steps-1])\n",
        "    frees_ = free2src(frees[steps-1])\n",
        "    src_free_lab = free2src(src_free)\n",
        "\n",
        "    ber = BER(mattes_, src_matte)\n",
        "    rmse = RMSE(frees_, src_free_lab)\n",
        "    s_rmse = RMSE(frees_ * src_matte, src_free_lab * src_matte)\n",
        "    print(\"[%d batch]\\tber : %f, rmse : %f, s_rmse : %f\" %(i+1, ber, rmse, s_rmse))\n",
        "\n",
        "    total_BER.append(ber)\n",
        "    total_RMSE.append(rmse)\n",
        "    total_SRMSE.append(s_rmse)\n",
        "\n",
        "    if i%10 == 10:\n",
        "      img_fname = SAVE_PATH + str(i) + \"_img.jpg\"\n",
        "      mat_fname = SAVE_PATH + str(i) + \"_matt.jpg\"\n",
        "      fre_fname = SAVE_PATH + str(i) + \"_free.jpg\"\n",
        "      # data out : to 'cpu'\n",
        "      img_out = image_.cpu()\n",
        "      save_batch(img_out, dprow, img_fname)\n",
        "      matt_out = mattes_.cpu()\n",
        "      save_batch(matt_out, dprow, mat_fname)\n",
        "      free_out = frees_.cpu()\n",
        "      save_batch_LAB(free_out, dprow, fre_fname)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "avg_BER = np.mean(total_BER)\n",
        "avg_RMSE = np.mean(total_RMSE)\n",
        "avg_SRMSE = np.mean(total_SRMSE)\n",
        "\n",
        "print(\"DONE============\")\n",
        "print(\"BER : %f\" %(avg_BER))\n",
        "print(\"RMSE : %f\" %(avg_RMSE))\n",
        "print(\"Shadow region RMSE : %f\" %(avg_SRMSE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 batch]\tber : 0.031697, rmse : 5.336680, s_rmse : 3.165593\n",
            "[2 batch]\tber : 0.029675, rmse : 2.893386, s_rmse : 1.594625\n",
            "[3 batch]\tber : 0.069604, rmse : 7.194751, s_rmse : 3.547878\n",
            "[4 batch]\tber : 0.039225, rmse : 4.845188, s_rmse : 1.494015\n",
            "[5 batch]\tber : 0.037525, rmse : 4.811147, s_rmse : 1.863109\n",
            "[6 batch]\tber : 0.019533, rmse : 3.613688, s_rmse : 1.509352\n",
            "[7 batch]\tber : 0.035284, rmse : 4.533610, s_rmse : 2.036932\n",
            "[8 batch]\tber : 0.015640, rmse : 3.757565, s_rmse : 1.795089\n",
            "[9 batch]\tber : 0.076878, rmse : 3.740987, s_rmse : 1.958181\n",
            "[10 batch]\tber : 0.014604, rmse : 3.873204, s_rmse : 1.770228\n",
            "[11 batch]\tber : 0.026468, rmse : 4.225317, s_rmse : 2.313511\n",
            "[12 batch]\tber : 0.018267, rmse : 7.145534, s_rmse : 3.883172\n",
            "[13 batch]\tber : 0.059398, rmse : 5.831346, s_rmse : 2.613397\n",
            "[14 batch]\tber : 0.045773, rmse : 6.937132, s_rmse : 3.446935\n",
            "[15 batch]\tber : 0.027680, rmse : 9.896238, s_rmse : 4.600909\n",
            "[16 batch]\tber : 0.011324, rmse : 7.861331, s_rmse : 4.200420\n",
            "[17 batch]\tber : 0.003312, rmse : 3.892902, s_rmse : 2.054683\n",
            "[18 batch]\tber : 0.007444, rmse : 4.402453, s_rmse : 2.275744\n",
            "[19 batch]\tber : 0.006721, rmse : 4.429379, s_rmse : 2.120103\n",
            "[20 batch]\tber : 0.011369, rmse : 5.486912, s_rmse : 1.922603\n",
            "[21 batch]\tber : 0.011755, rmse : 4.409788, s_rmse : 1.930738\n",
            "[22 batch]\tber : 0.016955, rmse : 3.875811, s_rmse : 1.800680\n",
            "[23 batch]\tber : 0.020670, rmse : 4.232456, s_rmse : 1.887947\n",
            "[24 batch]\tber : 0.030649, rmse : 3.087613, s_rmse : 1.354493\n",
            "[25 batch]\tber : 0.008739, rmse : 4.794261, s_rmse : 2.372080\n",
            "[26 batch]\tber : 0.015159, rmse : 4.766266, s_rmse : 2.500386\n",
            "[27 batch]\tber : 0.006247, rmse : 3.689630, s_rmse : 1.459721\n",
            "[28 batch]\tber : 0.004665, rmse : 4.248278, s_rmse : 1.926170\n",
            "[29 batch]\tber : 0.004294, rmse : 4.804821, s_rmse : 1.857913\n",
            "[30 batch]\tber : 0.007858, rmse : 3.994737, s_rmse : 1.683205\n",
            "[31 batch]\tber : 0.005672, rmse : 4.561375, s_rmse : 1.898421\n",
            "[32 batch]\tber : 0.023388, rmse : 3.522620, s_rmse : 1.118227\n",
            "[33 batch]\tber : 0.021060, rmse : 4.082918, s_rmse : 2.135207\n",
            "[34 batch]\tber : 0.020192, rmse : 3.537652, s_rmse : 1.530645\n",
            "[35 batch]\tber : 0.021414, rmse : 4.223457, s_rmse : 1.735451\n",
            "[36 batch]\tber : 0.040559, rmse : 4.690358, s_rmse : 1.153681\n",
            "[37 batch]\tber : 0.016897, rmse : 5.442074, s_rmse : 2.566858\n",
            "[38 batch]\tber : 0.034262, rmse : 5.686115, s_rmse : 2.365963\n",
            "[39 batch]\tber : 0.177714, rmse : 9.236685, s_rmse : 2.669993\n",
            "[40 batch]\tber : 0.201907, rmse : 9.108597, s_rmse : 2.177368\n",
            "[41 batch]\tber : 0.262441, rmse : 8.559951, s_rmse : 3.335384\n",
            "[42 batch]\tber : 0.350885, rmse : 9.597274, s_rmse : 3.903667\n",
            "[43 batch]\tber : 0.152402, rmse : 7.620311, s_rmse : 3.356735\n",
            "[44 batch]\tber : 0.200174, rmse : 8.144707, s_rmse : 3.082460\n",
            "[45 batch]\tber : 0.155962, rmse : 7.672833, s_rmse : 3.756392\n",
            "[46 batch]\tber : 0.024572, rmse : 6.876410, s_rmse : 5.072291\n",
            "[47 batch]\tber : 0.017155, rmse : 6.808133, s_rmse : 5.053001\n",
            "[48 batch]\tber : 0.042511, rmse : 5.168361, s_rmse : 3.002544\n",
            "[49 batch]\tber : 0.014411, rmse : 3.498943, s_rmse : 1.500185\n",
            "[50 batch]\tber : 0.025390, rmse : 2.884469, s_rmse : 0.621941\n",
            "[51 batch]\tber : 0.003268, rmse : 5.906604, s_rmse : 2.489049\n",
            "[52 batch]\tber : 0.007909, rmse : 3.705002, s_rmse : 2.133532\n",
            "[53 batch]\tber : 0.016845, rmse : 3.844792, s_rmse : 1.751310\n",
            "[54 batch]\tber : 0.008187, rmse : 4.519423, s_rmse : 3.274434\n",
            "[55 batch]\tber : 0.008084, rmse : 4.370858, s_rmse : 2.331748\n",
            "[56 batch]\tber : 0.016801, rmse : 4.735232, s_rmse : 2.548634\n",
            "[57 batch]\tber : 0.300935, rmse : 3.911353, s_rmse : 1.687504\n",
            "[58 batch]\tber : 0.121221, rmse : 5.555508, s_rmse : 2.594985\n",
            "[59 batch]\tber : 0.298558, rmse : 4.380291, s_rmse : 1.998725\n",
            "[60 batch]\tber : 0.076657, rmse : 5.132447, s_rmse : 2.040124\n",
            "[61 batch]\tber : 0.115478, rmse : 4.904014, s_rmse : 2.181523\n",
            "[62 batch]\tber : 0.130522, rmse : 4.916455, s_rmse : 1.801063\n",
            "[63 batch]\tber : 0.051652, rmse : 6.578675, s_rmse : 2.991260\n",
            "[64 batch]\tber : 0.093919, rmse : 9.411808, s_rmse : 5.593750\n",
            "[65 batch]\tber : 0.114957, rmse : 11.270292, s_rmse : 7.237857\n",
            "[66 batch]\tber : 0.107827, rmse : 11.414830, s_rmse : 8.579917\n",
            "[67 batch]\tber : 0.155672, rmse : 11.058460, s_rmse : 6.116122\n",
            "[68 batch]\tber : 0.088893, rmse : 8.565285, s_rmse : 3.297725\n",
            "[69 batch]\tber : 0.016452, rmse : 5.587162, s_rmse : 2.999937\n",
            "[70 batch]\tber : 0.021531, rmse : 4.415798, s_rmse : 2.456583\n",
            "[71 batch]\tber : 0.017121, rmse : 3.531111, s_rmse : 1.807325\n",
            "[72 batch]\tber : 0.034817, rmse : 4.340691, s_rmse : 2.037369\n",
            "[73 batch]\tber : 0.156370, rmse : 5.785944, s_rmse : 2.389259\n",
            "[74 batch]\tber : 0.042219, rmse : 5.386569, s_rmse : 2.050729\n",
            "[75 batch]\tber : 0.074821, rmse : 6.517032, s_rmse : 3.068696\n",
            "[76 batch]\tber : 0.072198, rmse : 7.074755, s_rmse : 3.609822\n",
            "[77 batch]\tber : 0.020041, rmse : 7.302032, s_rmse : 2.575336\n",
            "[78 batch]\tber : 0.017050, rmse : 7.940979, s_rmse : 3.135379\n",
            "[79 batch]\tber : 0.019115, rmse : 7.422598, s_rmse : 3.005195\n",
            "[80 batch]\tber : 0.098727, rmse : 6.892803, s_rmse : 2.372956\n",
            "[81 batch]\tber : 0.152551, rmse : 7.402065, s_rmse : 1.846973\n",
            "[82 batch]\tber : 0.119432, rmse : 7.127149, s_rmse : 2.719175\n",
            "[83 batch]\tber : 0.142263, rmse : 7.711230, s_rmse : 2.302481\n",
            "[84 batch]\tber : 0.037472, rmse : 5.105305, s_rmse : 2.912272\n",
            "[85 batch]\tber : 0.040508, rmse : 4.793646, s_rmse : 2.685496\n",
            "[86 batch]\tber : 0.057802, rmse : 5.153256, s_rmse : 2.891300\n",
            "[87 batch]\tber : 0.119821, rmse : 6.620414, s_rmse : 3.150585\n",
            "[88 batch]\tber : 0.052801, rmse : 7.521260, s_rmse : 3.860535\n",
            "[89 batch]\tber : 0.026447, rmse : 4.223581, s_rmse : 1.604104\n",
            "[90 batch]\tber : 0.019669, rmse : 5.934586, s_rmse : 3.020064\n",
            "[91 batch]\tber : 0.004837, rmse : 6.513312, s_rmse : 3.182343\n",
            "[92 batch]\tber : 0.064203, rmse : 7.792346, s_rmse : 2.206625\n",
            "[93 batch]\tber : 0.265139, rmse : 10.020068, s_rmse : 2.845162\n",
            "[94 batch]\tber : 0.092276, rmse : 9.645144, s_rmse : 4.391488\n",
            "[95 batch]\tber : 0.077506, rmse : 9.277904, s_rmse : 4.880620\n",
            "[96 batch]\tber : 0.022404, rmse : 3.986667, s_rmse : 2.470423\n",
            "[97 batch]\tber : 0.037479, rmse : 4.334162, s_rmse : 2.741098\n",
            "[98 batch]\tber : 0.014757, rmse : 7.564878, s_rmse : 3.940231\n",
            "[99 batch]\tber : 0.018431, rmse : 6.699981, s_rmse : 3.652664\n",
            "[100 batch]\tber : 0.030237, rmse : 4.641409, s_rmse : 2.319674\n",
            "[101 batch]\tber : 0.043509, rmse : 4.974872, s_rmse : 1.827965\n",
            "[102 batch]\tber : 0.007613, rmse : 6.740928, s_rmse : 2.996887\n",
            "[103 batch]\tber : 0.006974, rmse : 6.519370, s_rmse : 2.433361\n",
            "[104 batch]\tber : 0.016284, rmse : 5.727262, s_rmse : 2.365484\n",
            "[105 batch]\tber : 0.010444, rmse : 9.224312, s_rmse : 4.188444\n",
            "[106 batch]\tber : 0.010342, rmse : 7.110157, s_rmse : 3.344806\n",
            "[107 batch]\tber : 0.036214, rmse : 6.888611, s_rmse : 2.970403\n",
            "[108 batch]\tber : 0.102398, rmse : 6.754734, s_rmse : 2.902241\n",
            "[109 batch]\tber : 0.090619, rmse : 8.060075, s_rmse : 3.360539\n",
            "[110 batch]\tber : 0.091078, rmse : 6.891557, s_rmse : 3.414320\n",
            "[111 batch]\tber : 0.088335, rmse : 5.954723, s_rmse : 2.672431\n",
            "[112 batch]\tber : 0.051686, rmse : 9.593884, s_rmse : 4.713994\n",
            "[113 batch]\tber : 0.064263, rmse : 9.222706, s_rmse : 3.643173\n",
            "[114 batch]\tber : 0.020931, rmse : 5.429210, s_rmse : 2.383044\n",
            "[115 batch]\tber : 0.010078, rmse : 5.232445, s_rmse : 1.966687\n",
            "[116 batch]\tber : 0.004558, rmse : 8.485308, s_rmse : 3.250883\n",
            "[117 batch]\tber : 0.002110, rmse : 6.948246, s_rmse : 2.620952\n",
            "[118 batch]\tber : 0.216918, rmse : 4.333229, s_rmse : 1.450537\n",
            "[119 batch]\tber : 0.158393, rmse : 7.332271, s_rmse : 3.162258\n",
            "[120 batch]\tber : 0.144455, rmse : 7.260896, s_rmse : 2.425951\n",
            "[121 batch]\tber : 0.095766, rmse : 8.052722, s_rmse : 3.547695\n",
            "[122 batch]\tber : 0.090298, rmse : 8.112666, s_rmse : 3.166767\n",
            "[123 batch]\tber : 0.335423, rmse : 4.205596, s_rmse : 2.030531\n",
            "[124 batch]\tber : 0.392593, rmse : 4.482156, s_rmse : 1.580234\n",
            "[125 batch]\tber : 0.058803, rmse : 3.586462, s_rmse : 2.040292\n",
            "[126 batch]\tber : 0.037286, rmse : 3.612898, s_rmse : 1.928056\n",
            "[127 batch]\tber : 0.058095, rmse : 3.748200, s_rmse : 2.835459\n",
            "[128 batch]\tber : 0.135138, rmse : 4.514182, s_rmse : 4.087279\n",
            "[129 batch]\tber : 0.424101, rmse : 3.548525, s_rmse : 2.465721\n",
            "[130 batch]\tber : 0.367587, rmse : 3.631576, s_rmse : 2.020502\n",
            "[131 batch]\tber : 0.137402, rmse : 5.131498, s_rmse : 2.386405\n",
            "[132 batch]\tber : 0.017681, rmse : 4.465528, s_rmse : 1.956554\n",
            "[133 batch]\tber : 0.025818, rmse : 5.687972, s_rmse : 2.092046\n",
            "[134 batch]\tber : 0.044682, rmse : 11.034363, s_rmse : 5.417260\n",
            "[135 batch]\tber : 0.027019, rmse : 9.115626, s_rmse : 3.712077\n",
            "DONE============\n",
            "BER : 0.071497\n",
            "RMSE : 5.982204\n",
            "Shadow region RMSE : 2.756434\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vFoWHI24RlJU"
      },
      "source": [
        "Network Evaluation with batch_size 1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iahAgZqKRqE1"
      },
      "source": [
        "batch_num = 1\n",
        "dprow = 1\n",
        "\n",
        "test_img = ARGAN_Dataset(test_path, src_trans=img2tensor, matt_trans=matt2tensor, is_test=True)\n",
        "testloader = torch.utils.data.DataLoader(test_img, batch_size=1, shuffle=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h_qStPf6RtSt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2477deb-d408-4a9e-df14-db6213a0ba55"
      },
      "source": [
        "# Generate Testset Output\n",
        "if torch.cuda.is_available:\n",
        "#  torch.cuda.empty_cache()\n",
        "#  dis_net.cuda()\n",
        "  gen_net.cuda()\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "gen_net.eval()\n",
        "#dis_net.eval()\n",
        "for m in gen_net.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        m.track_running_stats = False\n",
        "\n",
        "PATH = '/content/drive/My Drive/KU/4/'\n",
        "gen_PATH = PATH + 'ARGAN256_gen_BN.pth'\n",
        "#dis_PATH = PATH + 'ARGAN256_dis_net.pth'\n",
        "SAVE_PATH = PATH + 'ARGAN256_test/zzz/'\n",
        "\n",
        "if os.path.isfile(gen_PATH):\n",
        "#  gen_net.load_state_dict(torch.load(gen_PATH, map_location=device))\n",
        "  gen_net.load_state_dict(torch.load(gen_PATH))\n",
        "else:\n",
        "  print(\"No trained Gen Net\")\n",
        "\"\"\"\n",
        "if os.path.isfile(dis_PATH):\n",
        "  dis_net.load_state_dict(torch.load(dis_PATH, map_location=device))\n",
        "else:\n",
        "  print(\"No trained Disc Net\")\n",
        "\"\"\"\n",
        "total_BER = []\n",
        "total_RMSE = []\n",
        "\n",
        "for i, datas in enumerate(testloader):\n",
        "  with torch.no_grad():\n",
        "    image, matte, free, src_matte, src_free = datas\n",
        "    image = image.to(device)\n",
        "    matte = matte.to(device)\n",
        "    free = free.to(device)\n",
        "    src_matte = src_matte.to(device)\n",
        "    src_free = src_free.to(device)\n",
        "\n",
        "    mattes, frees = gen_net(image)\n",
        "\n",
        "    image_ = matt2src(image)\n",
        "    mattes_ = matt2src(mattes[steps-1])\n",
        "    frees_ = free2src(frees[steps-1])\n",
        "    src_free_lab = free2src(src_free)\n",
        "\n",
        "    ber = BER(mattes_, src_matte)\n",
        "    rmse = RMSE(frees_, src_free_lab)\n",
        "    print(\"[%d image]\\tber : %f, rmse : %f\" %(i+1, ber, rmse))\n",
        "\n",
        "    total_BER.append(ber)\n",
        "    total_RMSE.append(rmse)\n",
        "\n",
        "\n",
        "    img_fname = SAVE_PATH + str(i) + \"_img.jpg\"\n",
        "    mat_fname = SAVE_PATH + str(i) + \"_matt.jpg\"\n",
        "    fre_fname = SAVE_PATH + str(i) + \"_free.jpg\"\n",
        "    gt_m_fname = SAVE_PATH + str(i) + \"_matt_gt.jpg\"\n",
        "    gt_f_fname = SAVE_PATH + str(i) + \"_free_gt.jpg\"\n",
        "\n",
        "    # data out : to 'cpu'\n",
        "    img_out = image_.cpu()\n",
        "    save_batch(img_out, dprow, img_fname)\n",
        "    matt_out = mattes_.cpu()\n",
        "    save_batch(matt_out, dprow, mat_fname)\n",
        "    free_out = frees_.cpu()\n",
        "    save_batch_LAB(free_out, dprow, fre_fname)\n",
        "    gt_m_out = src_matte.cpu()\n",
        "    save_batch(gt_m_out, dprow, gt_m_fname)\n",
        "    gt_f_out = src_free.cpu()\n",
        "    save_batch(gt_f_out, dprow, gt_f_fname)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "avg_BER = np.mean(total_BER)\n",
        "avg_RMSE = np.mean(total_RMSE)\n",
        "\n",
        "print(\"DONE============\")\n",
        "print(\"BER : %f\" %(avg_BER))\n",
        "print(\"RMSE : %f\" %(avg_RMSE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 image]\tber : 0.026574, rmse : 4.532673\n",
            "[2 image]\tber : 0.020301, rmse : 7.038940\n",
            "[3 image]\tber : 0.042702, rmse : 5.012364\n",
            "[4 image]\tber : 0.036504, rmse : 4.324929\n",
            "[5 image]\tber : 0.033626, rmse : 2.895464\n",
            "[6 image]\tber : 0.019955, rmse : 2.931724\n",
            "[7 image]\tber : 0.024172, rmse : 2.855391\n",
            "[8 image]\tber : 0.040451, rmse : 2.890459\n",
            "[9 image]\tber : 0.024752, rmse : 5.514907\n",
            "[10 image]\tber : 0.081063, rmse : 6.431958\n",
            "[11 image]\tber : 0.103735, rmse : 10.223772\n",
            "[12 image]\tber : 0.075263, rmse : 5.545083\n",
            "[13 image]\tber : 0.040020, rmse : 4.391103\n",
            "[14 image]\tber : 0.041718, rmse : 4.524572\n",
            "[15 image]\tber : 0.039346, rmse : 4.404221\n",
            "[16 image]\tber : 0.037194, rmse : 5.895140\n",
            "[17 image]\tber : 0.035893, rmse : 5.775198\n",
            "[18 image]\tber : 0.041946, rmse : 4.461034\n",
            "[19 image]\tber : 0.038854, rmse : 4.504193\n",
            "[20 image]\tber : 0.033634, rmse : 4.364290\n",
            "[21 image]\tber : 0.006324, rmse : 4.265287\n",
            "[22 image]\tber : 0.034213, rmse : 3.063166\n",
            "[23 image]\tber : 0.037318, rmse : 3.506435\n",
            "[24 image]\tber : 0.025169, rmse : 3.516277\n",
            "[25 image]\tber : 0.033876, rmse : 6.314459\n",
            "[26 image]\tber : 0.116424, rmse : 3.218216\n",
            "[27 image]\tber : 0.034772, rmse : 3.611014\n",
            "[28 image]\tber : 0.027315, rmse : 4.352671\n",
            "[29 image]\tber : 0.013985, rmse : 4.014264\n",
            "[30 image]\tber : 0.010122, rmse : 3.932358\n",
            "[31 image]\tber : 0.019626, rmse : 3.586028\n",
            "[32 image]\tber : 0.018171, rmse : 3.469848\n",
            "[33 image]\tber : 0.028494, rmse : 3.792842\n",
            "[34 image]\tber : 0.296115, rmse : 3.659594\n",
            "[35 image]\tber : 0.338224, rmse : 3.646278\n",
            "[36 image]\tber : 0.011737, rmse : 3.860870\n",
            "[37 image]\tber : 0.009833, rmse : 4.593323\n",
            "[38 image]\tber : 0.025319, rmse : 3.656198\n",
            "[39 image]\tber : 0.012653, rmse : 3.526812\n",
            "[40 image]\tber : 0.012371, rmse : 3.619673\n",
            "[41 image]\tber : 0.019276, rmse : 3.679965\n",
            "[42 image]\tber : 0.032962, rmse : 3.719266\n",
            "[43 image]\tber : 0.071164, rmse : 3.412762\n",
            "[44 image]\tber : 0.037763, rmse : 5.691325\n",
            "[45 image]\tber : 0.003862, rmse : 8.442653\n",
            "[46 image]\tber : 0.004495, rmse : 7.165269\n",
            "[47 image]\tber : 0.014723, rmse : 6.637548\n",
            "[48 image]\tber : 0.047107, rmse : 6.128467\n",
            "[49 image]\tber : 0.038229, rmse : 6.044250\n",
            "[50 image]\tber : 0.068228, rmse : 5.676285\n",
            "[51 image]\tber : 0.077197, rmse : 5.864781\n",
            "[52 image]\tber : 0.054343, rmse : 5.733199\n",
            "[53 image]\tber : 0.068493, rmse : 5.834851\n",
            "[54 image]\tber : 0.056807, rmse : 6.279726\n",
            "[55 image]\tber : 0.006399, rmse : 9.431799\n",
            "[56 image]\tber : 0.046588, rmse : 5.482330\n",
            "[57 image]\tber : 0.074894, rmse : 5.913480\n",
            "[58 image]\tber : 0.008889, rmse : 11.545577\n",
            "[59 image]\tber : 0.006706, rmse : 10.067293\n",
            "[60 image]\tber : 0.005437, rmse : 11.050889\n",
            "[61 image]\tber : 0.003558, rmse : 8.273629\n",
            "[62 image]\tber : 0.007225, rmse : 7.018795\n",
            "[63 image]\tber : 0.026117, rmse : 6.455636\n",
            "[64 image]\tber : 0.006021, rmse : 9.370721\n",
            "[65 image]\tber : 0.003770, rmse : 5.389322\n",
            "[66 image]\tber : 0.005682, rmse : 2.173690\n",
            "[67 image]\tber : 0.007109, rmse : 2.117491\n",
            "[68 image]\tber : 0.004959, rmse : 4.729193\n",
            "[69 image]\tber : 0.007850, rmse : 3.799400\n",
            "[70 image]\tber : 0.014022, rmse : 2.576587\n",
            "[71 image]\tber : 0.011486, rmse : 2.762794\n",
            "[72 image]\tber : 0.006035, rmse : 6.987067\n",
            "[73 image]\tber : 0.009150, rmse : 2.719159\n",
            "[74 image]\tber : 0.005510, rmse : 3.240873\n",
            "[75 image]\tber : 0.006249, rmse : 2.298746\n",
            "[76 image]\tber : 0.007910, rmse : 7.436146\n",
            "[77 image]\tber : 0.017296, rmse : 4.139341\n",
            "[78 image]\tber : 0.024880, rmse : 4.206167\n",
            "[79 image]\tber : 0.005934, rmse : 7.448624\n",
            "[80 image]\tber : 0.008489, rmse : 5.487881\n",
            "[81 image]\tber : 0.002863, rmse : 5.650607\n",
            "[82 image]\tber : 0.026055, rmse : 3.790231\n",
            "[83 image]\tber : 0.012678, rmse : 3.814274\n",
            "[84 image]\tber : 0.014327, rmse : 4.115948\n",
            "[85 image]\tber : 0.017980, rmse : 4.256709\n",
            "[86 image]\tber : 0.020147, rmse : 4.127631\n",
            "[87 image]\tber : 0.008155, rmse : 3.753451\n",
            "[88 image]\tber : 0.026524, rmse : 3.292771\n",
            "[89 image]\tber : 0.015689, rmse : 4.257211\n",
            "[90 image]\tber : 0.019506, rmse : 3.444973\n",
            "[91 image]\tber : 0.014410, rmse : 5.427099\n",
            "[92 image]\tber : 0.034263, rmse : 3.494230\n",
            "[93 image]\tber : 0.025219, rmse : 3.447834\n",
            "[94 image]\tber : 0.028060, rmse : 3.291080\n",
            "[95 image]\tber : 0.036225, rmse : 2.809705\n",
            "[96 image]\tber : 0.040599, rmse : 2.742298\n",
            "[97 image]\tber : 0.008904, rmse : 3.766316\n",
            "[98 image]\tber : 0.007845, rmse : 5.716780\n",
            "[99 image]\tber : 0.006333, rmse : 5.705596\n",
            "[100 image]\tber : 0.013085, rmse : 3.538252\n",
            "[101 image]\tber : 0.042661, rmse : 2.990213\n",
            "[102 image]\tber : 0.008357, rmse : 4.572327\n",
            "[103 image]\tber : 0.008169, rmse : 4.482503\n",
            "[104 image]\tber : 0.013971, rmse : 6.397560\n",
            "[105 image]\tber : 0.005103, rmse : 5.431098\n",
            "[106 image]\tber : 0.019473, rmse : 2.854457\n",
            "[107 image]\tber : 0.005518, rmse : 2.885736\n",
            "[108 image]\tber : 0.004602, rmse : 2.912256\n",
            "[109 image]\tber : 0.005659, rmse : 2.899551\n",
            "[110 image]\tber : 0.003325, rmse : 5.553979\n",
            "[111 image]\tber : 0.003391, rmse : 4.895590\n",
            "[112 image]\tber : 0.009414, rmse : 2.995092\n",
            "[113 image]\tber : 0.003476, rmse : 5.029429\n",
            "[114 image]\tber : 0.004173, rmse : 5.150270\n",
            "[115 image]\tber : 0.005929, rmse : 4.935988\n",
            "[116 image]\tber : 0.003772, rmse : 4.020050\n",
            "[117 image]\tber : 0.008304, rmse : 4.057049\n",
            "[118 image]\tber : 0.008074, rmse : 4.086343\n",
            "[119 image]\tber : 0.005957, rmse : 4.057282\n",
            "[120 image]\tber : 0.008755, rmse : 3.769923\n",
            "[121 image]\tber : 0.002842, rmse : 3.902587\n",
            "[122 image]\tber : 0.005045, rmse : 5.288604\n",
            "[123 image]\tber : 0.004565, rmse : 5.240900\n",
            "[124 image]\tber : 0.023453, rmse : 3.543730\n",
            "[125 image]\tber : 0.036120, rmse : 2.534951\n",
            "[126 image]\tber : 0.025364, rmse : 4.105522\n",
            "[127 image]\tber : 0.018262, rmse : 3.532058\n",
            "[128 image]\tber : 0.030675, rmse : 3.725411\n",
            "[129 image]\tber : 0.032720, rmse : 3.666029\n",
            "[130 image]\tber : 0.044139, rmse : 3.680255\n",
            "[131 image]\tber : 0.003936, rmse : 4.411243\n",
            "[132 image]\tber : 0.014778, rmse : 4.498642\n",
            "[133 image]\tber : 0.008920, rmse : 4.255931\n",
            "[134 image]\tber : 0.018287, rmse : 3.196844\n",
            "[135 image]\tber : 0.019532, rmse : 3.134237\n",
            "[136 image]\tber : 0.034973, rmse : 3.450175\n",
            "[137 image]\tber : 0.040280, rmse : 3.275311\n",
            "[138 image]\tber : 0.018663, rmse : 3.642369\n",
            "[139 image]\tber : 0.013250, rmse : 3.821535\n",
            "[140 image]\tber : 0.020588, rmse : 5.722912\n",
            "[141 image]\tber : 0.048720, rmse : 4.464817\n",
            "[142 image]\tber : 0.013815, rmse : 4.791865\n",
            "[143 image]\tber : 0.024115, rmse : 4.849599\n",
            "[144 image]\tber : 0.088456, rmse : 4.645713\n",
            "[145 image]\tber : 0.039624, rmse : 4.348452\n",
            "[146 image]\tber : 0.018830, rmse : 6.333566\n",
            "[147 image]\tber : 0.005576, rmse : 5.960075\n",
            "[148 image]\tber : 0.004215, rmse : 4.890714\n",
            "[149 image]\tber : 0.130560, rmse : 4.166028\n",
            "[150 image]\tber : 0.016317, rmse : 6.793341\n",
            "[151 image]\tber : 0.015417, rmse : 5.740771\n",
            "[152 image]\tber : 0.021200, rmse : 5.732881\n",
            "[153 image]\tber : 0.176807, rmse : 9.116609\n",
            "[154 image]\tber : 0.142734, rmse : 9.427707\n",
            "[155 image]\tber : 0.189521, rmse : 9.188924\n",
            "[156 image]\tber : 0.196084, rmse : 9.210585\n",
            "[157 image]\tber : 0.227371, rmse : 8.949868\n",
            "[158 image]\tber : 0.140247, rmse : 9.054396\n",
            "[159 image]\tber : 0.238605, rmse : 9.126119\n",
            "[160 image]\tber : 0.174256, rmse : 9.300425\n",
            "[161 image]\tber : 0.139721, rmse : 9.160890\n",
            "[162 image]\tber : 0.182831, rmse : 7.730305\n",
            "[163 image]\tber : 0.185203, rmse : 7.713279\n",
            "[164 image]\tber : 0.360338, rmse : 9.482450\n",
            "[165 image]\tber : 0.192348, rmse : 8.323832\n",
            "[166 image]\tber : 0.321893, rmse : 9.856463\n",
            "[167 image]\tber : 0.471436, rmse : 11.032517\n",
            "[168 image]\tber : 0.318565, rmse : 8.959809\n",
            "[169 image]\tber : 0.167140, rmse : 8.655334\n",
            "[170 image]\tber : 0.158064, rmse : 7.869811\n",
            "[171 image]\tber : 0.133840, rmse : 7.284501\n",
            "[172 image]\tber : 0.152037, rmse : 6.508756\n",
            "[173 image]\tber : 0.189097, rmse : 8.556689\n",
            "[174 image]\tber : 0.208541, rmse : 7.913649\n",
            "[175 image]\tber : 0.203536, rmse : 8.271212\n",
            "[176 image]\tber : 0.181168, rmse : 7.815962\n",
            "[177 image]\tber : 0.216754, rmse : 6.812439\n",
            "[178 image]\tber : 0.193124, rmse : 7.055877\n",
            "[179 image]\tber : 0.207360, rmse : 7.996070\n",
            "[180 image]\tber : 0.008482, rmse : 8.680877\n",
            "[181 image]\tber : 0.042505, rmse : 5.860238\n",
            "[182 image]\tber : 0.050662, rmse : 5.870210\n",
            "[183 image]\tber : 0.014253, rmse : 7.973533\n",
            "[184 image]\tber : 0.008388, rmse : 7.533993\n",
            "[185 image]\tber : 0.006448, rmse : 8.001237\n",
            "[186 image]\tber : 0.008893, rmse : 7.505657\n",
            "[187 image]\tber : 0.018061, rmse : 5.551133\n",
            "[188 image]\tber : 0.043883, rmse : 5.850890\n",
            "[189 image]\tber : 0.109637, rmse : 5.818640\n",
            "[190 image]\tber : 0.073571, rmse : 6.087589\n",
            "[191 image]\tber : 0.005534, rmse : 4.307753\n",
            "[192 image]\tber : 0.005438, rmse : 4.168425\n",
            "[193 image]\tber : 0.023488, rmse : 3.851411\n",
            "[194 image]\tber : 0.010474, rmse : 3.909154\n",
            "[195 image]\tber : 0.016285, rmse : 3.043920\n",
            "[196 image]\tber : 0.008419, rmse : 3.096792\n",
            "[197 image]\tber : 0.020599, rmse : 2.972835\n",
            "[198 image]\tber : 0.026793, rmse : 2.920713\n",
            "[199 image]\tber : 0.021093, rmse : 2.800545\n",
            "[200 image]\tber : 0.031280, rmse : 2.840649\n",
            "[201 image]\tber : 0.004002, rmse : 7.737075\n",
            "[202 image]\tber : 0.002705, rmse : 5.208018\n",
            "[203 image]\tber : 0.001850, rmse : 4.379373\n",
            "[204 image]\tber : 0.004934, rmse : 5.778163\n",
            "[205 image]\tber : 0.005143, rmse : 3.779775\n",
            "[206 image]\tber : 0.005221, rmse : 3.936807\n",
            "[207 image]\tber : 0.006822, rmse : 3.869825\n",
            "[208 image]\tber : 0.014277, rmse : 3.185507\n",
            "[209 image]\tber : 0.031802, rmse : 3.788560\n",
            "[210 image]\tber : 0.019869, rmse : 3.688163\n",
            "[211 image]\tber : 0.011595, rmse : 3.507044\n",
            "[212 image]\tber : 0.010749, rmse : 4.344494\n",
            "[213 image]\tber : 0.009833, rmse : 4.443425\n",
            "[214 image]\tber : 0.007764, rmse : 4.641795\n",
            "[215 image]\tber : 0.007901, rmse : 4.827066\n",
            "[216 image]\tber : 0.006495, rmse : 4.136409\n",
            "[217 image]\tber : 0.008483, rmse : 4.029438\n",
            "[218 image]\tber : 0.006341, rmse : 5.550308\n",
            "[219 image]\tber : 0.011818, rmse : 3.883438\n",
            "[220 image]\tber : 0.008316, rmse : 3.780768\n",
            "[221 image]\tber : 0.009450, rmse : 4.423862\n",
            "[222 image]\tber : 0.016476, rmse : 3.486335\n",
            "[223 image]\tber : 0.010472, rmse : 3.548087\n",
            "[224 image]\tber : 0.036138, rmse : 6.736146\n",
            "[225 image]\tber : 0.152855, rmse : 3.774884\n",
            "[226 image]\tber : 0.188499, rmse : 3.766536\n",
            "[227 image]\tber : 0.366280, rmse : 3.973088\n",
            "[228 image]\tber : 0.381210, rmse : 4.119801\n",
            "[229 image]\tber : 0.213456, rmse : 4.739021\n",
            "[230 image]\tber : 0.111400, rmse : 6.521449\n",
            "[231 image]\tber : 0.079313, rmse : 5.543081\n",
            "[232 image]\tber : 0.096561, rmse : 5.267002\n",
            "[233 image]\tber : 0.190698, rmse : 5.149823\n",
            "[234 image]\tber : 0.359484, rmse : 4.915900\n",
            "[235 image]\tber : 0.352814, rmse : 3.772601\n",
            "[236 image]\tber : 0.309821, rmse : 3.439265\n",
            "[237 image]\tber : 0.355743, rmse : 3.381346\n",
            "[238 image]\tber : 0.024491, rmse : 6.057333\n",
            "[239 image]\tber : 0.041892, rmse : 6.072262\n",
            "[240 image]\tber : 0.067324, rmse : 4.513412\n",
            "[241 image]\tber : 0.047256, rmse : 5.849923\n",
            "[242 image]\tber : 0.125068, rmse : 4.452978\n",
            "[243 image]\tber : 0.121461, rmse : 4.221581\n",
            "[244 image]\tber : 0.164944, rmse : 4.932043\n",
            "[245 image]\tber : 0.112770, rmse : 3.801687\n",
            "[246 image]\tber : 0.358647, rmse : 4.274543\n",
            "[247 image]\tber : 0.381304, rmse : 3.900254\n",
            "[248 image]\tber : 0.076392, rmse : 6.982092\n",
            "[249 image]\tber : 0.065457, rmse : 6.355000\n",
            "[250 image]\tber : 0.056881, rmse : 6.257051\n",
            "[251 image]\tber : 0.050243, rmse : 6.814496\n",
            "[252 image]\tber : 0.037281, rmse : 6.865989\n",
            "[253 image]\tber : 0.049625, rmse : 7.702527\n",
            "[254 image]\tber : 0.051021, rmse : 6.433578\n",
            "[255 image]\tber : 0.107972, rmse : 11.312004\n",
            "[256 image]\tber : 0.208849, rmse : 11.209247\n",
            "[257 image]\tber : 0.078449, rmse : 11.336921\n",
            "[258 image]\tber : 0.140728, rmse : 11.002664\n",
            "[259 image]\tber : 0.112638, rmse : 11.234312\n",
            "[260 image]\tber : 0.111752, rmse : 11.501468\n",
            "[261 image]\tber : 0.113454, rmse : 11.812958\n",
            "[262 image]\tber : 0.121436, rmse : 11.611712\n",
            "[263 image]\tber : 0.092752, rmse : 11.155659\n",
            "[264 image]\tber : 0.109659, rmse : 11.061953\n",
            "[265 image]\tber : 0.210476, rmse : 10.809035\n",
            "[266 image]\tber : 0.216126, rmse : 10.839874\n",
            "[267 image]\tber : 0.218376, rmse : 10.896006\n",
            "[268 image]\tber : 0.073846, rmse : 11.666068\n",
            "[269 image]\tber : 0.213441, rmse : 11.342290\n",
            "[270 image]\tber : 0.166835, rmse : 11.215219\n",
            "[271 image]\tber : 0.023663, rmse : 3.343288\n",
            "[272 image]\tber : 0.010528, rmse : 5.277329\n",
            "[273 image]\tber : 0.010293, rmse : 5.122600\n",
            "[274 image]\tber : 0.009881, rmse : 5.072792\n",
            "[275 image]\tber : 0.008171, rmse : 5.051465\n",
            "[276 image]\tber : 0.035490, rmse : 6.882877\n",
            "[277 image]\tber : 0.013290, rmse : 5.998466\n",
            "[278 image]\tber : 0.018638, rmse : 3.827772\n",
            "[279 image]\tber : 0.020639, rmse : 3.648078\n",
            "[280 image]\tber : 0.042533, rmse : 3.749024\n",
            "[281 image]\tber : 0.014510, rmse : 3.376562\n",
            "[282 image]\tber : 0.018933, rmse : 3.413563\n",
            "[283 image]\tber : 0.016425, rmse : 3.550799\n",
            "[284 image]\tber : 0.018566, rmse : 3.770042\n",
            "[285 image]\tber : 0.009851, rmse : 5.210561\n",
            "[286 image]\tber : 0.021692, rmse : 3.577851\n",
            "[287 image]\tber : 0.050514, rmse : 4.069233\n",
            "[288 image]\tber : 0.057670, rmse : 4.342437\n",
            "[289 image]\tber : 0.133713, rmse : 6.723798\n",
            "[290 image]\tber : 0.179633, rmse : 6.702159\n",
            "[291 image]\tber : 0.184834, rmse : 4.544095\n",
            "[292 image]\tber : 0.042896, rmse : 4.809513\n",
            "[293 image]\tber : 0.028259, rmse : 4.239166\n",
            "[294 image]\tber : 0.042026, rmse : 4.067001\n",
            "[295 image]\tber : 0.043579, rmse : 3.945871\n",
            "[296 image]\tber : 0.030720, rmse : 8.122781\n",
            "[297 image]\tber : 0.035768, rmse : 7.070579\n",
            "[298 image]\tber : 0.110137, rmse : 6.110911\n",
            "[299 image]\tber : 0.115941, rmse : 5.270139\n",
            "[300 image]\tber : 0.062524, rmse : 7.401090\n",
            "[301 image]\tber : 0.076787, rmse : 6.289496\n",
            "[302 image]\tber : 0.088099, rmse : 5.508502\n",
            "[303 image]\tber : 0.093579, rmse : 5.118705\n",
            "[304 image]\tber : 0.032769, rmse : 10.203241\n",
            "[305 image]\tber : 0.015373, rmse : 8.297456\n",
            "[306 image]\tber : 0.024998, rmse : 8.250493\n",
            "[307 image]\tber : 0.028674, rmse : 6.092873\n",
            "[308 image]\tber : 0.022701, rmse : 6.263957\n",
            "[309 image]\tber : 0.019233, rmse : 6.138673\n",
            "[310 image]\tber : 0.011127, rmse : 6.142207\n",
            "[311 image]\tber : 0.018017, rmse : 9.491611\n",
            "[312 image]\tber : 0.013831, rmse : 9.313210\n",
            "[313 image]\tber : 0.011481, rmse : 9.145108\n",
            "[314 image]\tber : 0.015856, rmse : 7.666878\n",
            "[315 image]\tber : 0.030156, rmse : 6.439400\n",
            "[316 image]\tber : 0.024927, rmse : 6.041519\n",
            "[317 image]\tber : 0.038272, rmse : 5.962094\n",
            "[318 image]\tber : 0.029855, rmse : 6.448956\n",
            "[319 image]\tber : 0.197872, rmse : 6.655012\n",
            "[320 image]\tber : 0.146879, rmse : 8.283608\n",
            "[321 image]\tber : 0.156877, rmse : 8.127767\n",
            "[322 image]\tber : 0.155589, rmse : 7.965490\n",
            "[323 image]\tber : 0.135791, rmse : 6.784807\n",
            "[324 image]\tber : 0.165698, rmse : 6.604471\n",
            "[325 image]\tber : 0.110346, rmse : 7.084440\n",
            "[326 image]\tber : 0.130023, rmse : 6.854167\n",
            "[327 image]\tber : 0.128296, rmse : 7.325966\n",
            "[328 image]\tber : 0.108093, rmse : 7.235074\n",
            "[329 image]\tber : 0.118268, rmse : 7.197621\n",
            "[330 image]\tber : 0.123583, rmse : 7.112214\n",
            "[331 image]\tber : 0.146499, rmse : 8.171369\n",
            "[332 image]\tber : 0.184062, rmse : 8.288043\n",
            "[333 image]\tber : 0.022286, rmse : 5.107170\n",
            "[334 image]\tber : 0.030065, rmse : 3.637709\n",
            "[335 image]\tber : 0.033096, rmse : 5.210596\n",
            "[336 image]\tber : 0.046572, rmse : 6.147368\n",
            "[337 image]\tber : 0.059770, rmse : 6.593400\n",
            "[338 image]\tber : 0.032575, rmse : 3.034410\n",
            "[339 image]\tber : 0.019920, rmse : 3.981770\n",
            "[340 image]\tber : 0.017956, rmse : 4.835402\n",
            "[341 image]\tber : 0.041716, rmse : 3.731228\n",
            "[342 image]\tber : 0.043915, rmse : 3.254931\n",
            "[343 image]\tber : 0.062210, rmse : 5.098678\n",
            "[344 image]\tber : 0.061132, rmse : 7.463983\n",
            "[345 image]\tber : 0.095235, rmse : 7.680782\n",
            "[346 image]\tber : 0.060167, rmse : 5.432977\n",
            "[347 image]\tber : 0.060711, rmse : 6.354407\n",
            "[348 image]\tber : 0.229333, rmse : 6.813911\n",
            "[349 image]\tber : 0.028806, rmse : 8.922690\n",
            "[350 image]\tber : 0.117662, rmse : 8.473756\n",
            "[351 image]\tber : 0.001550, rmse : 7.698586\n",
            "[352 image]\tber : 0.036050, rmse : 3.948447\n",
            "[353 image]\tber : 0.021033, rmse : 4.091272\n",
            "[354 image]\tber : 0.034452, rmse : 4.324877\n",
            "[355 image]\tber : 0.027085, rmse : 4.306986\n",
            "[356 image]\tber : 0.020135, rmse : 4.166697\n",
            "[357 image]\tber : 0.026306, rmse : 4.327176\n",
            "[358 image]\tber : 0.027659, rmse : 4.273113\n",
            "[359 image]\tber : 0.008598, rmse : 7.020219\n",
            "[360 image]\tber : 0.025017, rmse : 7.389845\n",
            "[361 image]\tber : 0.005723, rmse : 7.094038\n",
            "[362 image]\tber : 0.007712, rmse : 6.891494\n",
            "[363 image]\tber : 0.004222, rmse : 6.046838\n",
            "[364 image]\tber : 0.002116, rmse : 5.942273\n",
            "[365 image]\tber : 0.005774, rmse : 5.147632\n",
            "[366 image]\tber : 0.040901, rmse : 4.101807\n",
            "[367 image]\tber : 0.111813, rmse : 10.172647\n",
            "[368 image]\tber : 0.174260, rmse : 9.801883\n",
            "[369 image]\tber : 0.349864, rmse : 9.882756\n",
            "[370 image]\tber : 0.244808, rmse : 10.061691\n",
            "[371 image]\tber : 0.263736, rmse : 10.142462\n",
            "[372 image]\tber : 0.250122, rmse : 9.991549\n",
            "[373 image]\tber : 0.102194, rmse : 9.544653\n",
            "[374 image]\tber : 0.111402, rmse : 9.796675\n",
            "[375 image]\tber : 0.077468, rmse : 9.591407\n",
            "[376 image]\tber : 0.075775, rmse : 9.645978\n",
            "[377 image]\tber : 0.083863, rmse : 9.373773\n",
            "[378 image]\tber : 0.069122, rmse : 8.936614\n",
            "[379 image]\tber : 0.081196, rmse : 9.455553\n",
            "[380 image]\tber : 0.071938, rmse : 9.337015\n",
            "[381 image]\tber : 0.006032, rmse : 2.942971\n",
            "[382 image]\tber : 0.021316, rmse : 4.259464\n",
            "[383 image]\tber : 0.027843, rmse : 4.271308\n",
            "[384 image]\tber : 0.029253, rmse : 4.304167\n",
            "[385 image]\tber : 0.039597, rmse : 4.449006\n",
            "[386 image]\tber : 0.054149, rmse : 4.580657\n",
            "[387 image]\tber : 0.032403, rmse : 4.225852\n",
            "[388 image]\tber : 0.025035, rmse : 4.062751\n",
            "[389 image]\tber : 0.042216, rmse : 4.436557\n",
            "[390 image]\tber : 0.009227, rmse : 8.334371\n",
            "[391 image]\tber : 0.003680, rmse : 8.170511\n",
            "[392 image]\tber : 0.006429, rmse : 8.544438\n",
            "[393 image]\tber : 0.019806, rmse : 7.062330\n",
            "[394 image]\tber : 0.033441, rmse : 7.136782\n",
            "[395 image]\tber : 0.007300, rmse : 6.190794\n",
            "[396 image]\tber : 0.014750, rmse : 6.357901\n",
            "[397 image]\tber : 0.020757, rmse : 3.640663\n",
            "[398 image]\tber : 0.021648, rmse : 4.793898\n",
            "[399 image]\tber : 0.048560, rmse : 5.010505\n",
            "[400 image]\tber : 0.039665, rmse : 4.982938\n",
            "[401 image]\tber : 0.041779, rmse : 5.059435\n",
            "[402 image]\tber : 0.035547, rmse : 4.900937\n",
            "[403 image]\tber : 0.029214, rmse : 4.941325\n",
            "[404 image]\tber : 0.061446, rmse : 4.996361\n",
            "[405 image]\tber : 0.018133, rmse : 5.094166\n",
            "[406 image]\tber : 0.019255, rmse : 5.021828\n",
            "[407 image]\tber : 0.003759, rmse : 8.393932\n",
            "[408 image]\tber : 0.002258, rmse : 7.754551\n",
            "[409 image]\tber : 0.003741, rmse : 6.506768\n",
            "[410 image]\tber : 0.008393, rmse : 6.545178\n",
            "[411 image]\tber : 0.009265, rmse : 6.497979\n",
            "[412 image]\tber : 0.007831, rmse : 6.527448\n",
            "[413 image]\tber : 0.020820, rmse : 5.606980\n",
            "[414 image]\tber : 0.043590, rmse : 4.975173\n",
            "[415 image]\tber : 0.006331, rmse : 4.802309\n",
            "[416 image]\tber : 0.021534, rmse : 7.207869\n",
            "[417 image]\tber : 0.017719, rmse : 7.318749\n",
            "[418 image]\tber : 0.025149, rmse : 6.316213\n",
            "[419 image]\tber : 0.004561, rmse : 11.341089\n",
            "[420 image]\tber : 0.004177, rmse : 10.875330\n",
            "[421 image]\tber : 0.004035, rmse : 7.824551\n",
            "[422 image]\tber : 0.005433, rmse : 7.849928\n",
            "[423 image]\tber : 0.016056, rmse : 6.086850\n",
            "[424 image]\tber : 0.024744, rmse : 6.505581\n",
            "[425 image]\tber : 0.026982, rmse : 6.309966\n",
            "[426 image]\tber : 0.016739, rmse : 7.386294\n",
            "[427 image]\tber : 0.031541, rmse : 7.773501\n",
            "[428 image]\tber : 0.085064, rmse : 5.917052\n",
            "[429 image]\tber : 0.099431, rmse : 5.747932\n",
            "[430 image]\tber : 0.095437, rmse : 5.916555\n",
            "[431 image]\tber : 0.147096, rmse : 7.279160\n",
            "[432 image]\tber : 0.085620, rmse : 7.840611\n",
            "[433 image]\tber : 0.082228, rmse : 8.003745\n",
            "[434 image]\tber : 0.098359, rmse : 8.289083\n",
            "[435 image]\tber : 0.088314, rmse : 8.298916\n",
            "[436 image]\tber : 0.093413, rmse : 7.630096\n",
            "[437 image]\tber : 0.084991, rmse : 6.632800\n",
            "[438 image]\tber : 0.107612, rmse : 6.010692\n",
            "[439 image]\tber : 0.083471, rmse : 8.329933\n",
            "[440 image]\tber : 0.086445, rmse : 6.361129\n",
            "[441 image]\tber : 0.121189, rmse : 7.774757\n",
            "[442 image]\tber : 0.063888, rmse : 5.466645\n",
            "[443 image]\tber : 0.059310, rmse : 5.098293\n",
            "[444 image]\tber : 0.078777, rmse : 5.050870\n",
            "[445 image]\tber : 0.038824, rmse : 9.225788\n",
            "[446 image]\tber : 0.038276, rmse : 9.270955\n",
            "[447 image]\tber : 0.050767, rmse : 11.316598\n",
            "[448 image]\tber : 0.072047, rmse : 8.308985\n",
            "[449 image]\tber : 0.042578, rmse : 7.911708\n",
            "[450 image]\tber : 0.167603, rmse : 10.681821\n",
            "[451 image]\tber : 0.079054, rmse : 6.223955\n",
            "[452 image]\tber : 0.006462, rmse : 11.171355\n",
            "[453 image]\tber : 0.018418, rmse : 5.501678\n",
            "[454 image]\tber : 0.023718, rmse : 5.463357\n",
            "[455 image]\tber : 0.021113, rmse : 5.431003\n",
            "[456 image]\tber : 0.020911, rmse : 5.319094\n",
            "[457 image]\tber : 0.017051, rmse : 5.314547\n",
            "[458 image]\tber : 0.007552, rmse : 5.368120\n",
            "[459 image]\tber : 0.009381, rmse : 5.097304\n",
            "[460 image]\tber : 0.007114, rmse : 5.144928\n",
            "[461 image]\tber : 0.009967, rmse : 5.174914\n",
            "[462 image]\tber : 0.003730, rmse : 10.450670\n",
            "[463 image]\tber : 0.004791, rmse : 9.064390\n",
            "[464 image]\tber : 0.002299, rmse : 8.357177\n",
            "[465 image]\tber : 0.002577, rmse : 6.663384\n",
            "[466 image]\tber : 0.002881, rmse : 5.810407\n",
            "[467 image]\tber : 0.002489, rmse : 7.970698\n",
            "[468 image]\tber : 0.001258, rmse : 7.170702\n",
            "[469 image]\tber : 0.015655, rmse : 5.371963\n",
            "[470 image]\tber : 0.281905, rmse : 5.595954\n",
            "[471 image]\tber : 0.471097, rmse : 2.770752\n",
            "[472 image]\tber : 0.397692, rmse : 2.694022\n",
            "[473 image]\tber : 0.103721, rmse : 8.370068\n",
            "[474 image]\tber : 0.168148, rmse : 6.428795\n",
            "[475 image]\tber : 0.197344, rmse : 7.043163\n",
            "[476 image]\tber : 0.166606, rmse : 7.352224\n",
            "[477 image]\tber : 0.125542, rmse : 7.181642\n",
            "[478 image]\tber : 0.154412, rmse : 7.406967\n",
            "[479 image]\tber : 0.143014, rmse : 6.933054\n",
            "[480 image]\tber : 0.154746, rmse : 7.508398\n",
            "[481 image]\tber : 0.108869, rmse : 7.265980\n",
            "[482 image]\tber : 0.096584, rmse : 7.978421\n",
            "[483 image]\tber : 0.101817, rmse : 8.764234\n",
            "[484 image]\tber : 0.076244, rmse : 8.131660\n",
            "[485 image]\tber : 0.093972, rmse : 8.593132\n",
            "[486 image]\tber : 0.082591, rmse : 8.791626\n",
            "[487 image]\tber : 0.081730, rmse : 7.778055\n",
            "[488 image]\tber : 0.102746, rmse : 7.185307\n",
            "[489 image]\tber : 0.063752, rmse : 4.294637\n",
            "[490 image]\tber : 0.332619, rmse : 4.159052\n",
            "[491 image]\tber : 0.488227, rmse : 4.238253\n",
            "[492 image]\tber : 0.382635, rmse : 4.128409\n",
            "[493 image]\tber : 0.391231, rmse : 3.898022\n",
            "[494 image]\tber : 0.341889, rmse : 4.668921\n",
            "[495 image]\tber : 0.483665, rmse : 4.680615\n",
            "[496 image]\tber : 0.370349, rmse : 4.632205\n",
            "[497 image]\tber : 0.142890, rmse : 3.892726\n",
            "[498 image]\tber : 0.026996, rmse : 3.020739\n",
            "[499 image]\tber : 0.022758, rmse : 4.025335\n",
            "[500 image]\tber : 0.008089, rmse : 3.312001\n",
            "[501 image]\tber : 0.039989, rmse : 4.059670\n",
            "[502 image]\tber : 0.020835, rmse : 3.706770\n",
            "[503 image]\tber : 0.053082, rmse : 3.251602\n",
            "[504 image]\tber : 0.041878, rmse : 3.379073\n",
            "[505 image]\tber : 0.025253, rmse : 2.815114\n",
            "[506 image]\tber : 0.013700, rmse : 3.692383\n",
            "[507 image]\tber : 0.094142, rmse : 3.908961\n",
            "[508 image]\tber : 0.091654, rmse : 4.399715\n",
            "[509 image]\tber : 0.070573, rmse : 4.861804\n",
            "[510 image]\tber : 0.140716, rmse : 4.652269\n",
            "[511 image]\tber : 0.271986, rmse : 4.508870\n",
            "[512 image]\tber : 0.052625, rmse : 3.987568\n",
            "[513 image]\tber : 0.500000, rmse : 3.279692\n",
            "[514 image]\tber : 0.474147, rmse : 2.936063\n",
            "[515 image]\tber : 0.502622, rmse : 3.100787\n",
            "[516 image]\tber : 0.368272, rmse : 4.623463\n",
            "[517 image]\tber : 0.407915, rmse : 4.051123\n",
            "[518 image]\tber : 0.325691, rmse : 3.673536\n",
            "[519 image]\tber : 0.362088, rmse : 3.619509\n",
            "[520 image]\tber : 0.369788, rmse : 3.121869\n",
            "[521 image]\tber : 0.447610, rmse : 3.518053\n",
            "[522 image]\tber : 0.371322, rmse : 3.163349\n",
            "[523 image]\tber : 0.002273, rmse : 6.485521\n",
            "[524 image]\tber : 0.002621, rmse : 6.394032\n",
            "[525 image]\tber : 0.008548, rmse : 5.130969\n",
            "[526 image]\tber : 0.009655, rmse : 5.404659\n",
            "[527 image]\tber : 0.036161, rmse : 3.477024\n",
            "[528 image]\tber : 0.042097, rmse : 3.483806\n",
            "[529 image]\tber : 0.006620, rmse : 3.944175\n",
            "[530 image]\tber : 0.014572, rmse : 3.935881\n",
            "[531 image]\tber : 0.013069, rmse : 4.163474\n",
            "[532 image]\tber : 0.048179, rmse : 9.001661\n",
            "[533 image]\tber : 0.032515, rmse : 12.230227\n",
            "[534 image]\tber : 0.040649, rmse : 12.270933\n",
            "[535 image]\tber : 0.056057, rmse : 9.718849\n",
            "[536 image]\tber : 0.045062, rmse : 9.613447\n",
            "[537 image]\tber : 0.028031, rmse : 8.712852\n",
            "[538 image]\tber : 0.034837, rmse : 8.649391\n",
            "[539 image]\tber : 0.025707, rmse : 8.797827\n",
            "[540 image]\tber : 0.026369, rmse : 10.210340\n",
            "DONE============\n",
            "BER : 0.074841\n",
            "RMSE : 5.892299\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kP51wBUCtmqo"
      },
      "source": [
        "# For test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIxiuE29tlGw",
        "outputId": "aa33bc99-5767-4cde-83b0-05132203c96d"
      },
      "source": [
        "# Evaluation with size recovering\n",
        "# No images saved\n",
        "if torch.cuda.is_available:\n",
        "  gen_net.cuda()\n",
        "  device = \"cuda:0\"\n",
        "\n",
        "gen_net.eval()\n",
        "for m in gen_net.modules():\n",
        "    if isinstance(m, nn.BatchNorm2d):\n",
        "        m.track_running_stats = False\n",
        "\n",
        "PATH = '/content/drive/My Drive/KU/4/'\n",
        "#gen_PATH = PATH + 'ARGAN256_gen_BL.pth'\n",
        "gen_PATH = PATH + 'ARGAN256_gen_BL.pth'\n",
        "\n",
        "if os.path.isfile(gen_PATH):\n",
        "  gen_net.load_state_dict(torch.load(gen_PATH))\n",
        "else:\n",
        "  print(\"No trained Gen Net\")\n",
        "\n",
        "total_BER = []\n",
        "total_sens = []\n",
        "total_spec = []\n",
        "total_RMSE = []\n",
        "\n",
        "for i, datas in enumerate(testloader):\n",
        "  with torch.no_grad():\n",
        "    image, matte, free, src_matte, src_free = datas\n",
        "    image = image.to(device)\n",
        "    matte = matte.to(device)\n",
        "    free = free.to(device)\n",
        "    src_matte = src_matte.to(device)\n",
        "    src_free = src_free.to(device)\n",
        "\n",
        "    mattes, frees = gen_net(image)\n",
        "\n",
        "    image_ = matt2src(image)\n",
        "    mattes_ = matt2src(mattes[steps-1])\n",
        "    frees_ = free2src(frees[steps-1])\n",
        "    src_free_lab = free2src(src_free)\n",
        "\n",
        "    sens, spec, ber = BERs(mattes_, src_matte)\n",
        "    rmse = RMSE(frees_, src_free_lab)\n",
        "    print(\"[%d image]\\tber : %f (%f / %f), rmse : %f\" %(i+1, ber, sens, spec, rmse))\n",
        "\n",
        "    total_BER.append(ber)\n",
        "    total_sens.append(sens)\n",
        "    total_spec.append(spec)\n",
        "    total_RMSE.append(rmse)\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "avg_BER = np.mean(total_BER)\n",
        "avg_sens = np.mean(total_sens)\n",
        "avg_spec = np.mean(total_spec)\n",
        "avg_RMSE = np.mean(total_RMSE)\n",
        "\n",
        "print(\"DONE============\")\n",
        "print(\"BER : %f\" %(avg_BER))\n",
        "print(\"sens : %f\" %(avg_sens))\n",
        "print(\"spec : %f\" %(avg_spec))\n",
        "print(\"RMSE : %f\" %(avg_RMSE))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 image]\tber : 0.006055 (0.997673 / 0.990217), rmse : 4.008686\n",
            "[2 image]\tber : 0.018797 (0.981029 / 0.981376), rmse : 6.761482\n",
            "[3 image]\tber : 0.034071 (0.942675 / 0.989183), rmse : 4.594495\n",
            "[4 image]\tber : 0.015643 (0.989570 / 0.979145), rmse : 3.413022\n",
            "[5 image]\tber : 0.021569 (0.976200 / 0.980662), rmse : 2.496001\n",
            "[6 image]\tber : 0.016291 (0.974692 / 0.992726), rmse : 2.792156\n",
            "[7 image]\tber : 0.023387 (0.965468 / 0.987758), rmse : 2.625678\n",
            "[8 image]\tber : 0.022112 (0.973510 / 0.982265), rmse : 2.478117\n",
            "[9 image]\tber : 0.001413 (0.998541 / 0.998633), rmse : 4.359787\n",
            "[10 image]\tber : 0.020153 (0.999948 / 0.959746), rmse : 4.880087\n",
            "[11 image]\tber : 0.039770 (0.934414 / 0.986046), rmse : 9.831825\n",
            "[12 image]\tber : 0.022752 (0.990128 / 0.964369), rmse : 4.109680\n",
            "[13 image]\tber : 0.033081 (0.985491 / 0.948346), rmse : 4.084582\n",
            "[14 image]\tber : 0.028034 (0.992741 / 0.951190), rmse : 4.086577\n",
            "[15 image]\tber : 0.028017 (0.992450 / 0.951515), rmse : 3.988919\n",
            "[16 image]\tber : 0.023324 (0.998670 / 0.954682), rmse : 5.529715\n",
            "[17 image]\tber : 0.023959 (0.998035 / 0.954047), rmse : 5.415451\n",
            "[18 image]\tber : 0.026610 (0.994635 / 0.952144), rmse : 4.006933\n",
            "[19 image]\tber : 0.026856 (0.996078 / 0.950210), rmse : 4.163756\n",
            "[20 image]\tber : 0.025215 (0.991364 / 0.958206), rmse : 4.084056\n",
            "[21 image]\tber : 0.022590 (0.956976 / 0.997844), rmse : 4.097579\n",
            "[22 image]\tber : 0.041403 (0.938372 / 0.978822), rmse : 2.888068\n",
            "[23 image]\tber : 0.029159 (0.963279 / 0.978403), rmse : 3.098236\n",
            "[24 image]\tber : 0.022895 (0.975800 / 0.978410), rmse : 3.064749\n",
            "[25 image]\tber : 0.133054 (0.764734 / 0.969157), rmse : 6.178041\n",
            "[26 image]\tber : 0.091532 (0.838018 / 0.978917), rmse : 2.862003\n",
            "[27 image]\tber : 0.022220 (0.982686 / 0.972874), rmse : 3.272771\n",
            "[28 image]\tber : 0.020671 (0.983018 / 0.975639), rmse : 3.924203\n",
            "[29 image]\tber : 0.020927 (0.962398 / 0.995748), rmse : 3.655374\n",
            "[30 image]\tber : 0.031797 (0.938579 / 0.997826), rmse : 3.636300\n",
            "[31 image]\tber : 0.016431 (0.989898 / 0.977240), rmse : 3.094361\n",
            "[32 image]\tber : 0.016579 (0.988392 / 0.978450), rmse : 3.037304\n",
            "[33 image]\tber : 0.029369 (0.952023 / 0.989240), rmse : 3.743665\n",
            "[34 image]\tber : 0.267779 (0.476315 / 0.988127), rmse : 3.652367\n",
            "[35 image]\tber : 0.369918 (0.270108 / 0.990057), rmse : 3.670484\n",
            "[36 image]\tber : 0.014385 (0.973367 / 0.997863), rmse : 3.775548\n",
            "[37 image]\tber : 0.003858 (0.994859 / 0.997426), rmse : 4.299955\n",
            "[38 image]\tber : 0.014733 (0.985741 / 0.984794), rmse : 3.425004\n",
            "[39 image]\tber : 0.018164 (0.977658 / 0.986014), rmse : 3.414246\n",
            "[40 image]\tber : 0.011900 (0.981339 / 0.994861), rmse : 3.506930\n",
            "[41 image]\tber : 0.018951 (0.976435 / 0.985663), rmse : 3.552319\n",
            "[42 image]\tber : 0.036912 (0.944438 / 0.981738), rmse : 3.616755\n",
            "[43 image]\tber : 0.058166 (0.898930 / 0.984737), rmse : 3.370884\n",
            "[44 image]\tber : 0.020763 (0.994403 / 0.964072), rmse : 5.253951\n",
            "[45 image]\tber : 0.002646 (0.998303 / 0.996405), rmse : 8.193419\n",
            "[46 image]\tber : 0.002666 (0.996985 / 0.997684), rmse : 6.830960\n",
            "[47 image]\tber : 0.003145 (0.994396 / 0.999313), rmse : 6.245586\n",
            "[48 image]\tber : 0.026612 (0.974814 / 0.971963), rmse : 5.553042\n",
            "[49 image]\tber : 0.024023 (0.982581 / 0.969374), rmse : 5.585740\n",
            "[50 image]\tber : 0.034135 (0.974057 / 0.957673), rmse : 5.112345\n",
            "[51 image]\tber : 0.048639 (0.975737 / 0.926985), rmse : 5.272610\n",
            "[52 image]\tber : 0.029819 (0.977399 / 0.962964), rmse : 5.253181\n",
            "[53 image]\tber : 0.036685 (0.966832 / 0.959799), rmse : 5.323106\n",
            "[54 image]\tber : 0.041211 (0.970856 / 0.946722), rmse : 5.878284\n",
            "[55 image]\tber : 0.005363 (0.998453 / 0.990821), rmse : 9.198526\n",
            "[56 image]\tber : 0.038558 (0.981370 / 0.941514), rmse : 5.109716\n",
            "[57 image]\tber : 0.043431 (0.958609 / 0.954528), rmse : 5.362875\n",
            "[58 image]\tber : 0.007493 (0.998053 / 0.986961), rmse : 11.327748\n",
            "[59 image]\tber : 0.005518 (0.997207 / 0.991757), rmse : 9.822703\n",
            "[60 image]\tber : 0.004176 (0.998681 / 0.992967), rmse : 10.790762\n",
            "[61 image]\tber : 0.003175 (0.997788 / 0.995861), rmse : 8.059702\n",
            "[62 image]\tber : 0.004376 (0.992860 / 0.998389), rmse : 6.585624\n",
            "[63 image]\tber : 0.007317 (0.991710 / 0.993656), rmse : 5.843718\n",
            "[64 image]\tber : 0.004844 (0.996430 / 0.993881), rmse : 9.123771\n",
            "[65 image]\tber : 0.001834 (0.999177 / 0.997154), rmse : 4.908514\n",
            "[66 image]\tber : 0.008455 (0.983228 / 0.999862), rmse : 1.738998\n",
            "[67 image]\tber : 0.007576 (0.985178 / 0.999670), rmse : 1.728959\n",
            "[68 image]\tber : 0.003024 (0.995328 / 0.998625), rmse : 4.219196\n",
            "[69 image]\tber : 0.003911 (0.993923 / 0.998256), rmse : 3.300769\n",
            "[70 image]\tber : 0.013831 (0.972530 / 0.999808), rmse : 2.264379\n",
            "[71 image]\tber : 0.006933 (0.986804 / 0.999330), rmse : 2.308860\n",
            "[72 image]\tber : 0.004642 (0.999547 / 0.991169), rmse : 6.771819\n",
            "[73 image]\tber : 0.010697 (0.979032 / 0.999573), rmse : 2.270070\n",
            "[74 image]\tber : 0.008015 (0.984595 / 0.999376), rmse : 2.654645\n",
            "[75 image]\tber : 0.007810 (0.984627 / 0.999754), rmse : 1.928792\n",
            "[76 image]\tber : 0.006117 (0.998245 / 0.989520), rmse : 7.170674\n",
            "[77 image]\tber : 0.018462 (0.977612 / 0.985465), rmse : 3.702729\n",
            "[78 image]\tber : 0.027326 (0.962711 / 0.982637), rmse : 3.778816\n",
            "[79 image]\tber : 0.005179 (0.997543 / 0.992099), rmse : 7.235142\n",
            "[80 image]\tber : 0.009003 (0.992078 / 0.989915), rmse : 5.197666\n",
            "[81 image]\tber : 0.002180 (0.996944 / 0.998697), rmse : 5.292356\n",
            "[82 image]\tber : 0.016834 (0.971601 / 0.994730), rmse : 3.488950\n",
            "[83 image]\tber : 0.014083 (0.992736 / 0.979098), rmse : 3.549170\n",
            "[84 image]\tber : 0.014231 (0.991702 / 0.979836), rmse : 3.667212\n",
            "[85 image]\tber : 0.017693 (0.988004 / 0.976609), rmse : 3.770117\n",
            "[86 image]\tber : 0.026742 (0.967756 / 0.978760), rmse : 3.764302\n",
            "[87 image]\tber : 0.006028 (0.995277 / 0.992667), rmse : 3.338009\n",
            "[88 image]\tber : 0.020794 (0.986486 / 0.971926), rmse : 2.741652\n",
            "[89 image]\tber : 0.007457 (0.994660 / 0.990427), rmse : 3.632437\n",
            "[90 image]\tber : 0.009246 (0.985228 / 0.996280), rmse : 2.767620\n",
            "[91 image]\tber : 0.014080 (0.996959 / 0.974881), rmse : 5.134070\n",
            "[92 image]\tber : 0.027578 (0.986137 / 0.958707), rmse : 2.971052\n",
            "[93 image]\tber : 0.016980 (0.991186 / 0.974853), rmse : 2.897641\n",
            "[94 image]\tber : 0.016879 (0.989163 / 0.977078), rmse : 2.712321\n",
            "[95 image]\tber : 0.033512 (0.972919 / 0.960057), rmse : 2.358996\n",
            "[96 image]\tber : 0.034835 (0.970380 / 0.959950), rmse : 2.346919\n",
            "[97 image]\tber : 0.006817 (0.996170 / 0.990195), rmse : 3.377318\n",
            "[98 image]\tber : 0.006290 (0.998957 / 0.988463), rmse : 5.410055\n",
            "[99 image]\tber : 0.006007 (0.998885 / 0.989101), rmse : 5.481811\n",
            "[100 image]\tber : 0.010272 (0.985596 / 0.993861), rmse : 3.029733\n",
            "[101 image]\tber : 0.033196 (0.958515 / 0.975093), rmse : 2.550027\n",
            "[102 image]\tber : 0.003412 (0.995359 / 0.997816), rmse : 4.082155\n",
            "[103 image]\tber : 0.005777 (0.996910 / 0.991536), rmse : 4.042294\n",
            "[104 image]\tber : 0.010766 (0.999366 / 0.979102), rmse : 6.191314\n",
            "[105 image]\tber : 0.003850 (0.993688 / 0.998613), rmse : 5.087162\n",
            "[106 image]\tber : 0.022714 (0.954636 / 0.999936), rmse : 2.547904\n",
            "[107 image]\tber : 0.009625 (0.980933 / 0.999818), rmse : 2.558155\n",
            "[108 image]\tber : 0.007879 (0.984407 / 0.999836), rmse : 2.563456\n",
            "[109 image]\tber : 0.008901 (0.982388 / 0.999811), rmse : 2.529530\n",
            "[110 image]\tber : 0.003119 (0.995340 / 0.998422), rmse : 5.233149\n",
            "[111 image]\tber : 0.004255 (0.992063 / 0.999427), rmse : 4.527251\n",
            "[112 image]\tber : 0.010922 (0.978376 / 0.999780), rmse : 2.573828\n",
            "[113 image]\tber : 0.002821 (0.996085 / 0.998273), rmse : 4.689039\n",
            "[114 image]\tber : 0.003761 (0.994374 / 0.998104), rmse : 4.671316\n",
            "[115 image]\tber : 0.003938 (0.993921 / 0.998204), rmse : 4.638983\n",
            "[116 image]\tber : 0.004940 (0.991301 / 0.998818), rmse : 3.582159\n",
            "[117 image]\tber : 0.008684 (0.983097 / 0.999534), rmse : 3.692874\n",
            "[118 image]\tber : 0.005455 (0.990333 / 0.998758), rmse : 3.684332\n",
            "[119 image]\tber : 0.007042 (0.987058 / 0.998858), rmse : 3.605328\n",
            "[120 image]\tber : 0.007409 (0.985390 / 0.999792), rmse : 3.451003\n",
            "[121 image]\tber : 0.003550 (0.993025 / 0.999875), rmse : 3.537951\n",
            "[122 image]\tber : 0.004577 (0.992205 / 0.998640), rmse : 4.932148\n",
            "[123 image]\tber : 0.003422 (0.995478 / 0.997678), rmse : 4.835212\n",
            "[124 image]\tber : 0.016909 (0.967172 / 0.999010), rmse : 3.156086\n",
            "[125 image]\tber : 0.020915 (0.958237 / 0.999934), rmse : 2.240737\n",
            "[126 image]\tber : 0.018568 (0.982454 / 0.980411), rmse : 3.786814\n",
            "[127 image]\tber : 0.034244 (0.970839 / 0.960673), rmse : 3.363513\n",
            "[128 image]\tber : 0.038279 (0.970254 / 0.953188), rmse : 3.466515\n",
            "[129 image]\tber : 0.044379 (0.960059 / 0.951182), rmse : 3.481508\n",
            "[130 image]\tber : 0.053284 (0.939031 / 0.954400), rmse : 3.467730\n",
            "[131 image]\tber : 0.005694 (0.989282 / 0.999329), rmse : 4.221790\n",
            "[132 image]\tber : 0.012899 (0.985949 / 0.988253), rmse : 4.321966\n",
            "[133 image]\tber : 0.009118 (0.989411 / 0.992352), rmse : 4.058564\n",
            "[134 image]\tber : 0.038214 (0.973019 / 0.950554), rmse : 3.156204\n",
            "[135 image]\tber : 0.034973 (0.968924 / 0.961129), rmse : 3.130510\n",
            "[136 image]\tber : 0.035680 (0.962384 / 0.966257), rmse : 3.264727\n",
            "[137 image]\tber : 0.043563 (0.953105 / 0.959769), rmse : 3.121185\n",
            "[138 image]\tber : 0.029367 (0.985323 / 0.955943), rmse : 3.404400\n",
            "[139 image]\tber : 0.008268 (0.994434 / 0.989030), rmse : 3.347398\n",
            "[140 image]\tber : 0.007056 (0.989813 / 0.996075), rmse : 5.190495\n",
            "[141 image]\tber : 0.045588 (0.910081 / 0.998743), rmse : 4.091804\n",
            "[142 image]\tber : 0.003573 (0.998964 / 0.993890), rmse : 4.262276\n",
            "[143 image]\tber : 0.006170 (0.999329 / 0.988331), rmse : 4.235756\n",
            "[144 image]\tber : 0.038147 (0.923998 / 0.999708), rmse : 4.180042\n",
            "[145 image]\tber : 0.019822 (0.995956 / 0.964399), rmse : 3.766335\n",
            "[146 image]\tber : 0.004011 (0.999214 / 0.992765), rmse : 5.904625\n",
            "[147 image]\tber : 0.002687 (0.998115 / 0.996511), rmse : 5.547728\n",
            "[148 image]\tber : 0.003042 (0.996992 / 0.996925), rmse : 4.459541\n",
            "[149 image]\tber : 0.044949 (0.913976 / 0.996126), rmse : 3.680312\n",
            "[150 image]\tber : 0.003552 (0.999768 / 0.993127), rmse : 6.358073\n",
            "[151 image]\tber : 0.004374 (0.998613 / 0.992639), rmse : 5.302457\n",
            "[152 image]\tber : 0.007928 (0.997557 / 0.986586), rmse : 5.278071\n",
            "[153 image]\tber : 0.234166 (0.809234 / 0.722434), rmse : 9.012955\n",
            "[154 image]\tber : 0.130240 (0.985119 / 0.754402), rmse : 9.321779\n",
            "[155 image]\tber : 0.164954 (0.952927 / 0.717166), rmse : 9.155801\n",
            "[156 image]\tber : 0.168812 (0.947106 / 0.715269), rmse : 9.202906\n",
            "[157 image]\tber : 0.203130 (0.873870 / 0.719869), rmse : 8.813443\n",
            "[158 image]\tber : 0.135672 (0.964911 / 0.763746), rmse : 9.035334\n",
            "[159 image]\tber : 0.209028 (0.900835 / 0.681108), rmse : 8.936558\n",
            "[160 image]\tber : 0.167832 (0.947592 / 0.716744), rmse : 9.216321\n",
            "[161 image]\tber : 0.123481 (0.999061 / 0.753976), rmse : 9.062364\n",
            "[162 image]\tber : 0.194888 (0.939735 / 0.670489), rmse : 7.781065\n",
            "[163 image]\tber : 0.206183 (0.943140 / 0.644494), rmse : 7.576376\n",
            "[164 image]\tber : 0.470729 (0.337677 / 0.720866), rmse : 9.497405\n",
            "[165 image]\tber : 0.229033 (0.864250 / 0.677685), rmse : 8.372028\n",
            "[166 image]\tber : 0.510598 (0.254720 / 0.724084), rmse : 9.958903\n",
            "[167 image]\tber : 0.517915 (0.152322 / 0.811848), rmse : 11.012359\n",
            "[168 image]\tber : 0.428106 (0.345761 / 0.798027), rmse : 8.914702\n",
            "[169 image]\tber : 0.243051 (0.792168 / 0.721729), rmse : 8.731557\n",
            "[170 image]\tber : 0.174934 (0.975979 / 0.674152), rmse : 7.665133\n",
            "[171 image]\tber : 0.170086 (0.977985 / 0.681843), rmse : 7.372953\n",
            "[172 image]\tber : 0.145681 (0.947422 / 0.761216), rmse : 5.596403\n",
            "[173 image]\tber : 0.129915 (0.901078 / 0.839092), rmse : 6.940700\n",
            "[174 image]\tber : 0.169785 (0.946324 / 0.714107), rmse : 6.469896\n",
            "[175 image]\tber : 0.092300 (0.929745 / 0.885655), rmse : 6.254791\n",
            "[176 image]\tber : 0.169383 (0.971111 / 0.690123), rmse : 7.082924\n",
            "[177 image]\tber : 0.218188 (0.883092 / 0.680532), rmse : 5.835700\n",
            "[178 image]\tber : 0.189436 (0.908437 / 0.712691), rmse : 5.887772\n",
            "[179 image]\tber : 0.187107 (0.898950 / 0.726836), rmse : 6.670734\n",
            "[180 image]\tber : 0.165745 (0.673763 / 0.994748), rmse : 9.155046\n",
            "[181 image]\tber : 0.044876 (0.925261 / 0.984987), rmse : 5.805935\n",
            "[182 image]\tber : 0.071951 (0.878203 / 0.977896), rmse : 5.958307\n",
            "[183 image]\tber : 0.144334 (0.714969 / 0.996364), rmse : 8.458808\n",
            "[184 image]\tber : 0.061879 (0.880870 / 0.995373), rmse : 7.683408\n",
            "[185 image]\tber : 0.013162 (0.977893 / 0.995783), rmse : 7.952969\n",
            "[186 image]\tber : 0.007205 (0.989975 / 0.995615), rmse : 7.244115\n",
            "[187 image]\tber : 0.022251 (0.972308 / 0.983191), rmse : 5.478339\n",
            "[188 image]\tber : 0.078343 (0.871748 / 0.971566), rmse : 5.959535\n",
            "[189 image]\tber : 0.160772 (0.691870 / 0.986586), rmse : 6.043256\n",
            "[190 image]\tber : 0.084954 (0.846545 / 0.983547), rmse : 6.080157\n",
            "[191 image]\tber : 0.004625 (0.991886 / 0.998863), rmse : 3.857192\n",
            "[192 image]\tber : 0.005000 (0.991062 / 0.998937), rmse : 3.696069\n",
            "[193 image]\tber : 0.011697 (0.977296 / 0.999311), rmse : 3.584549\n",
            "[194 image]\tber : 0.007140 (0.986710 / 0.999010), rmse : 3.600032\n",
            "[195 image]\tber : 0.011875 (0.976719 / 0.999531), rmse : 2.794033\n",
            "[196 image]\tber : 0.007839 (0.985246 / 0.999077), rmse : 2.811092\n",
            "[197 image]\tber : 0.018497 (0.963079 / 0.999927), rmse : 2.667803\n",
            "[198 image]\tber : 0.029824 (0.940653 / 0.999699), rmse : 2.646732\n",
            "[199 image]\tber : 0.025073 (0.949926 / 0.999927), rmse : 2.512396\n",
            "[200 image]\tber : 0.031115 (0.937842 / 0.999927), rmse : 2.539240\n",
            "[201 image]\tber : 0.003527 (0.997783 / 0.995163), rmse : 7.495304\n",
            "[202 image]\tber : 0.002280 (0.996982 / 0.998458), rmse : 4.910962\n",
            "[203 image]\tber : 0.002570 (0.994957 / 0.999904), rmse : 4.059319\n",
            "[204 image]\tber : 0.003732 (0.995532 / 0.997004), rmse : 5.410661\n",
            "[205 image]\tber : 0.007006 (0.986501 / 0.999488), rmse : 3.391605\n",
            "[206 image]\tber : 0.006272 (0.988212 / 0.999244), rmse : 3.545923\n",
            "[207 image]\tber : 0.006017 (0.988635 / 0.999330), rmse : 3.502779\n",
            "[208 image]\tber : 0.009212 (0.982400 / 0.999176), rmse : 2.745586\n",
            "[209 image]\tber : 0.026277 (0.947541 / 0.999905), rmse : 3.857234\n",
            "[210 image]\tber : 0.014691 (0.974300 / 0.996318), rmse : 3.669804\n",
            "[211 image]\tber : 0.016251 (0.967823 / 0.999675), rmse : 3.527661\n",
            "[212 image]\tber : 0.009299 (0.982462 / 0.998940), rmse : 4.094891\n",
            "[213 image]\tber : 0.007249 (0.988923 / 0.996580), rmse : 4.344602\n",
            "[214 image]\tber : 0.014894 (0.970965 / 0.999247), rmse : 4.792743\n",
            "[215 image]\tber : 0.007172 (0.986687 / 0.998970), rmse : 4.942847\n",
            "[216 image]\tber : 0.007078 (0.986134 / 0.999711), rmse : 3.953793\n",
            "[217 image]\tber : 0.012419 (0.975290 / 0.999873), rmse : 3.830417\n",
            "[218 image]\tber : 0.006945 (0.988672 / 0.997439), rmse : 5.400805\n",
            "[219 image]\tber : 0.005843 (0.989054 / 0.999260), rmse : 3.735744\n",
            "[220 image]\tber : 0.006374 (0.988434 / 0.998817), rmse : 3.675411\n",
            "[221 image]\tber : 0.013379 (0.973833 / 0.999408), rmse : 4.473443\n",
            "[222 image]\tber : 0.018826 (0.962501 / 0.999847), rmse : 3.497039\n",
            "[223 image]\tber : 0.013140 (0.974059 / 0.999660), rmse : 3.540599\n",
            "[224 image]\tber : 0.154858 (0.722449 / 0.967835), rmse : 6.483355\n",
            "[225 image]\tber : 0.147516 (0.730396 / 0.974573), rmse : 3.370226\n",
            "[226 image]\tber : 0.239586 (0.535242 / 0.985586), rmse : 3.199010\n",
            "[227 image]\tber : 0.329822 (0.356441 / 0.983914), rmse : 3.538971\n",
            "[228 image]\tber : 0.362984 (0.293201 / 0.980830), rmse : 3.857198\n",
            "[229 image]\tber : 0.200611 (0.614321 / 0.984458), rmse : 4.055962\n",
            "[230 image]\tber : 0.199734 (0.632308 / 0.968225), rmse : 6.401084\n",
            "[231 image]\tber : 0.088050 (0.884512 / 0.939389), rmse : 5.040888\n",
            "[232 image]\tber : 0.097668 (0.828783 / 0.975881), rmse : 4.608922\n",
            "[233 image]\tber : 0.174304 (0.677221 / 0.974172), rmse : 4.561316\n",
            "[234 image]\tber : 0.324836 (0.351343 / 0.998986), rmse : 4.646194\n",
            "[235 image]\tber : 0.330264 (0.353992 / 0.985480), rmse : 3.247550\n",
            "[236 image]\tber : 0.272191 (0.468486 / 0.987133), rmse : 3.078186\n",
            "[237 image]\tber : 0.349490 (0.314042 / 0.986977), rmse : 3.012308\n",
            "[238 image]\tber : 0.017581 (0.989477 / 0.975361), rmse : 5.695516\n",
            "[239 image]\tber : 0.036771 (0.978320 / 0.948138), rmse : 5.781471\n",
            "[240 image]\tber : 0.071062 (0.917446 / 0.940431), rmse : 4.300805\n",
            "[241 image]\tber : 0.032974 (0.963661 / 0.970390), rmse : 5.587413\n",
            "[242 image]\tber : 0.111855 (0.835239 / 0.941051), rmse : 4.199702\n",
            "[243 image]\tber : 0.101932 (0.868853 / 0.927284), rmse : 4.054832\n",
            "[244 image]\tber : 0.136156 (0.800901 / 0.926788), rmse : 4.748360\n",
            "[245 image]\tber : 0.120973 (0.812026 / 0.946027), rmse : 3.893965\n",
            "[246 image]\tber : 0.344060 (0.359981 / 0.951899), rmse : 4.182513\n",
            "[247 image]\tber : 0.355297 (0.347588 / 0.941817), rmse : 4.005019\n",
            "[248 image]\tber : 0.071076 (0.900738 / 0.957111), rmse : 6.635100\n",
            "[249 image]\tber : 0.074807 (0.899160 / 0.951227), rmse : 5.992659\n",
            "[250 image]\tber : 0.051904 (0.936223 / 0.959970), rmse : 5.834175\n",
            "[251 image]\tber : 0.040272 (0.962649 / 0.956807), rmse : 6.347267\n",
            "[252 image]\tber : 0.043022 (0.948033 / 0.965923), rmse : 6.411845\n",
            "[253 image]\tber : 0.035952 (0.981570 / 0.946526), rmse : 7.325963\n",
            "[254 image]\tber : 0.041077 (0.963008 / 0.954838), rmse : 5.926497\n",
            "[255 image]\tber : 0.141457 (0.943344 / 0.773741), rmse : 11.125200\n",
            "[256 image]\tber : 0.220659 (0.780283 / 0.778398), rmse : 11.136218\n",
            "[257 image]\tber : 0.120005 (0.934927 / 0.825063), rmse : 11.131210\n",
            "[258 image]\tber : 0.153423 (0.994730 / 0.698424), rmse : 10.884290\n",
            "[259 image]\tber : 0.119084 (0.993274 / 0.768557), rmse : 11.319157\n",
            "[260 image]\tber : 0.141597 (0.905184 / 0.811623), rmse : 11.523798\n",
            "[261 image]\tber : 0.161796 (0.867580 / 0.808828), rmse : 11.843367\n",
            "[262 image]\tber : 0.178228 (0.826472 / 0.817073), rmse : 11.576951\n",
            "[263 image]\tber : 0.143410 (0.942924 / 0.770256), rmse : 10.969152\n",
            "[264 image]\tber : 0.147602 (0.966063 / 0.738733), rmse : 10.826254\n",
            "[265 image]\tber : 0.221198 (0.793706 / 0.763898), rmse : 10.783244\n",
            "[266 image]\tber : 0.224837 (0.781065 / 0.769262), rmse : 10.809568\n",
            "[267 image]\tber : 0.224889 (0.783389 / 0.766833), rmse : 10.874734\n",
            "[268 image]\tber : 0.117793 (0.928546 / 0.835867), rmse : 11.361211\n",
            "[269 image]\tber : 0.234097 (0.757733 / 0.774074), rmse : 11.306494\n",
            "[270 image]\tber : 0.184902 (0.855153 / 0.775043), rmse : 11.188420\n",
            "[271 image]\tber : 0.030204 (0.941438 / 0.998153), rmse : 3.405162\n",
            "[272 image]\tber : 0.008504 (0.990597 / 0.992396), rmse : 4.970092\n",
            "[273 image]\tber : 0.009938 (0.987272 / 0.992852), rmse : 4.924973\n",
            "[274 image]\tber : 0.009000 (0.986522 / 0.995478), rmse : 4.859544\n",
            "[275 image]\tber : 0.006483 (0.994006 / 0.993027), rmse : 4.780962\n",
            "[276 image]\tber : 0.026208 (0.961783 / 0.985802), rmse : 6.628891\n",
            "[277 image]\tber : 0.011305 (0.983302 / 0.994088), rmse : 5.778640\n",
            "[278 image]\tber : 0.021799 (0.958743 / 0.997660), rmse : 3.623390\n",
            "[279 image]\tber : 0.022479 (0.957289 / 0.997754), rmse : 3.452615\n",
            "[280 image]\tber : 0.048070 (0.905118 / 0.998742), rmse : 3.616515\n",
            "[281 image]\tber : 0.012833 (0.977445 / 0.996890), rmse : 3.150630\n",
            "[282 image]\tber : 0.018306 (0.966039 / 0.997348), rmse : 3.220073\n",
            "[283 image]\tber : 0.022990 (0.955829 / 0.998191), rmse : 3.359968\n",
            "[284 image]\tber : 0.026632 (0.949314 / 0.997422), rmse : 3.567963\n",
            "[285 image]\tber : 0.009109 (0.986557 / 0.995226), rmse : 5.027765\n",
            "[286 image]\tber : 0.015607 (0.972327 / 0.996460), rmse : 3.027385\n",
            "[287 image]\tber : 0.031053 (0.955689 / 0.982205), rmse : 3.393708\n",
            "[288 image]\tber : 0.033455 (0.954430 / 0.978660), rmse : 3.612401\n",
            "[289 image]\tber : 0.126676 (0.759858 / 0.986790), rmse : 5.999111\n",
            "[290 image]\tber : 0.158688 (0.695457 / 0.987166), rmse : 5.976718\n",
            "[291 image]\tber : 0.148268 (0.706213 / 0.997250), rmse : 3.811289\n",
            "[292 image]\tber : 0.006482 (0.991914 / 0.995122), rmse : 3.943090\n",
            "[293 image]\tber : 0.012173 (0.979743 / 0.995910), rmse : 3.531841\n",
            "[294 image]\tber : 0.018674 (0.966587 / 0.996065), rmse : 3.205098\n",
            "[295 image]\tber : 0.029311 (0.943934 / 0.997444), rmse : 3.155574\n",
            "[296 image]\tber : 0.085493 (0.839437 / 0.989577), rmse : 7.771652\n",
            "[297 image]\tber : 0.048518 (0.909789 / 0.993175), rmse : 6.604705\n",
            "[298 image]\tber : 0.133503 (0.737201 / 0.995793), rmse : 5.781463\n",
            "[299 image]\tber : 0.138148 (0.725854 / 0.997850), rmse : 4.950968\n",
            "[300 image]\tber : 0.019618 (0.975091 / 0.985672), rmse : 6.675602\n",
            "[301 image]\tber : 0.053341 (0.911507 / 0.981810), rmse : 5.644796\n",
            "[302 image]\tber : 0.086282 (0.834620 / 0.992817), rmse : 4.935472\n",
            "[303 image]\tber : 0.082821 (0.840786 / 0.993572), rmse : 4.466615\n",
            "[304 image]\tber : 0.043444 (0.920528 / 0.992583), rmse : 9.806553\n",
            "[305 image]\tber : 0.010102 (0.988573 / 0.991223), rmse : 7.710177\n",
            "[306 image]\tber : 0.014897 (0.977908 / 0.992299), rmse : 7.649259\n",
            "[307 image]\tber : 0.021071 (0.959439 / 0.998420), rmse : 5.451869\n",
            "[308 image]\tber : 0.014006 (0.973774 / 0.998215), rmse : 5.528348\n",
            "[309 image]\tber : 0.016780 (0.967804 / 0.998635), rmse : 5.425750\n",
            "[310 image]\tber : 0.011356 (0.980404 / 0.996883), rmse : 5.513670\n",
            "[311 image]\tber : 0.011178 (0.984716 / 0.992928), rmse : 9.087652\n",
            "[312 image]\tber : 0.009286 (0.990378 / 0.991050), rmse : 8.855615\n",
            "[313 image]\tber : 0.008915 (0.990726 / 0.991444), rmse : 8.750311\n",
            "[314 image]\tber : 0.010452 (0.986469 / 0.992627), rmse : 7.038620\n",
            "[315 image]\tber : 0.029745 (0.941928 / 0.998582), rmse : 5.902780\n",
            "[316 image]\tber : 0.024096 (0.955814 / 0.995994), rmse : 5.371542\n",
            "[317 image]\tber : 0.032513 (0.939180 / 0.995794), rmse : 5.353228\n",
            "[318 image]\tber : 0.011220 (0.988096 / 0.989463), rmse : 5.613600\n",
            "[319 image]\tber : 0.210786 (0.812058 / 0.766370), rmse : 6.473128\n",
            "[320 image]\tber : 0.141435 (0.911682 / 0.805448), rmse : 7.914419\n",
            "[321 image]\tber : 0.151338 (0.905545 / 0.791779), rmse : 7.801776\n",
            "[322 image]\tber : 0.151605 (0.908013 / 0.788776), rmse : 7.572641\n",
            "[323 image]\tber : 0.121922 (0.965732 / 0.790424), rmse : 6.691937\n",
            "[324 image]\tber : 0.172437 (0.868036 / 0.787090), rmse : 6.530920\n",
            "[325 image]\tber : 0.111708 (0.965771 / 0.810813), rmse : 6.737395\n",
            "[326 image]\tber : 0.131366 (0.921782 / 0.815485), rmse : 6.688135\n",
            "[327 image]\tber : 0.129833 (0.927073 / 0.813262), rmse : 7.142838\n",
            "[328 image]\tber : 0.113674 (0.963616 / 0.809036), rmse : 6.986962\n",
            "[329 image]\tber : 0.123184 (0.965956 / 0.787675), rmse : 7.010968\n",
            "[330 image]\tber : 0.129154 (0.955530 / 0.786161), rmse : 7.040802\n",
            "[331 image]\tber : 0.207963 (0.761835 / 0.822238), rmse : 7.910472\n",
            "[332 image]\tber : 0.227237 (0.718182 / 0.827343), rmse : 8.040692\n",
            "[333 image]\tber : 0.012542 (0.983771 / 0.991144), rmse : 4.895116\n",
            "[334 image]\tber : 0.014201 (0.985530 / 0.986067), rmse : 3.104337\n",
            "[335 image]\tber : 0.012279 (0.984570 / 0.990873), rmse : 4.884552\n",
            "[336 image]\tber : 0.053661 (0.905457 / 0.987221), rmse : 6.125936\n",
            "[337 image]\tber : 0.064223 (0.893246 / 0.978309), rmse : 6.558827\n",
            "[338 image]\tber : 0.022088 (0.981597 / 0.974228), rmse : 2.882820\n",
            "[339 image]\tber : 0.013195 (0.987159 / 0.986450), rmse : 3.485254\n",
            "[340 image]\tber : 0.012512 (0.983450 / 0.991526), rmse : 4.473002\n",
            "[341 image]\tber : 0.016042 (0.983958 / 0.983958), rmse : 3.136585\n",
            "[342 image]\tber : 0.027210 (0.956746 / 0.988834), rmse : 2.922255\n",
            "[343 image]\tber : 0.082845 (0.871591 / 0.962719), rmse : 5.435400\n",
            "[344 image]\tber : 0.172022 (0.668943 / 0.987014), rmse : 7.402961\n",
            "[345 image]\tber : 0.218938 (0.574858 / 0.987266), rmse : 7.755099\n",
            "[346 image]\tber : 0.069720 (0.891447 / 0.969112), rmse : 5.485120\n",
            "[347 image]\tber : 0.143756 (0.738494 / 0.973993), rmse : 6.628807\n",
            "[348 image]\tber : 0.327895 (0.360992 / 0.983218), rmse : 7.128283\n",
            "[349 image]\tber : 0.077003 (0.868495 / 0.977498), rmse : 8.935550\n",
            "[350 image]\tber : 0.253544 (0.510729 / 0.982184), rmse : 8.517357\n",
            "[351 image]\tber : 0.001262 (0.999410 / 0.998066), rmse : 7.309740\n",
            "[352 image]\tber : 0.043110 (0.914889 / 0.998890), rmse : 3.460118\n",
            "[353 image]\tber : 0.023311 (0.954652 / 0.998726), rmse : 3.460326\n",
            "[354 image]\tber : 0.018898 (0.964063 / 0.998141), rmse : 3.515624\n",
            "[355 image]\tber : 0.019759 (0.965937 / 0.994545), rmse : 3.610435\n",
            "[356 image]\tber : 0.020662 (0.960068 / 0.998608), rmse : 3.635076\n",
            "[357 image]\tber : 0.023241 (0.955446 / 0.998073), rmse : 3.721058\n",
            "[358 image]\tber : 0.026679 (0.949572 / 0.997070), rmse : 3.710550\n",
            "[359 image]\tber : 0.001594 (0.999094 / 0.997718), rmse : 6.590309\n",
            "[360 image]\tber : 0.002384 (0.998384 / 0.996848), rmse : 6.895560\n",
            "[361 image]\tber : 0.002713 (0.996931 / 0.997643), rmse : 6.671890\n",
            "[362 image]\tber : 0.002560 (0.997784 / 0.997097), rmse : 6.492558\n",
            "[363 image]\tber : 0.001677 (0.997710 / 0.998937), rmse : 5.617642\n",
            "[364 image]\tber : 0.001709 (0.997048 / 0.999533), rmse : 5.472561\n",
            "[365 image]\tber : 0.002223 (0.995679 / 0.999874), rmse : 4.516924\n",
            "[366 image]\tber : 0.035538 (0.931267 / 0.997658), rmse : 3.461047\n",
            "[367 image]\tber : 0.100133 (0.929400 / 0.870335), rmse : 9.983443\n",
            "[368 image]\tber : 0.162530 (0.826565 / 0.848375), rmse : 9.423185\n",
            "[369 image]\tber : 0.367281 (0.422089 / 0.843349), rmse : 9.527718\n",
            "[370 image]\tber : 0.274284 (0.604305 / 0.847128), rmse : 9.668180\n",
            "[371 image]\tber : 0.279749 (0.598758 / 0.841744), rmse : 9.750127\n",
            "[372 image]\tber : 0.265444 (0.624173 / 0.844939), rmse : 9.596958\n",
            "[373 image]\tber : 0.102773 (0.917226 / 0.877229), rmse : 9.386966\n",
            "[374 image]\tber : 0.113002 (0.903187 / 0.870808), rmse : 9.643981\n",
            "[375 image]\tber : 0.088562 (0.923876 / 0.899001), rmse : 9.488470\n",
            "[376 image]\tber : 0.095544 (0.903665 / 0.905247), rmse : 9.599176\n",
            "[377 image]\tber : 0.111715 (0.866862 / 0.909708), rmse : 9.332740\n",
            "[378 image]\tber : 0.074795 (0.944183 / 0.906227), rmse : 8.806943\n",
            "[379 image]\tber : 0.095847 (0.909599 / 0.898708), rmse : 9.353530\n",
            "[380 image]\tber : 0.080188 (0.933841 / 0.905784), rmse : 9.218371\n",
            "[381 image]\tber : 0.009622 (0.981723 / 0.999033), rmse : 2.619947\n",
            "[382 image]\tber : 0.015168 (0.974959 / 0.994706), rmse : 3.673981\n",
            "[383 image]\tber : 0.017469 (0.971177 / 0.993884), rmse : 3.658475\n",
            "[384 image]\tber : 0.026840 (0.951330 / 0.994990), rmse : 3.736192\n",
            "[385 image]\tber : 0.029798 (0.950723 / 0.989681), rmse : 3.814107\n",
            "[386 image]\tber : 0.032187 (0.946901 / 0.988726), rmse : 3.858814\n",
            "[387 image]\tber : 0.024746 (0.957140 / 0.993368), rmse : 3.580454\n",
            "[388 image]\tber : 0.026142 (0.952817 / 0.994898), rmse : 3.579161\n",
            "[389 image]\tber : 0.028819 (0.954755 / 0.987607), rmse : 3.766335\n",
            "[390 image]\tber : 0.002498 (0.999379 / 0.995626), rmse : 7.843992\n",
            "[391 image]\tber : 0.002176 (0.999264 / 0.996384), rmse : 7.823493\n",
            "[392 image]\tber : 0.004254 (0.997264 / 0.994229), rmse : 8.188076\n",
            "[393 image]\tber : 0.005053 (0.993708 / 0.996186), rmse : 6.479005\n",
            "[394 image]\tber : 0.003456 (0.995716 / 0.997372), rmse : 6.495089\n",
            "[395 image]\tber : 0.005659 (0.993860 / 0.994823), rmse : 5.697771\n",
            "[396 image]\tber : 0.003398 (0.995250 / 0.997954), rmse : 5.731744\n",
            "[397 image]\tber : 0.026947 (0.948337 / 0.997769), rmse : 3.448078\n",
            "[398 image]\tber : 0.021714 (0.956571 / 1.000000), rmse : 4.587324\n",
            "[399 image]\tber : 0.055386 (0.891658 / 0.997569), rmse : 4.796246\n",
            "[400 image]\tber : 0.047304 (0.907666 / 0.997726), rmse : 4.752557\n",
            "[401 image]\tber : 0.042295 (0.918211 / 0.997200), rmse : 4.803007\n",
            "[402 image]\tber : 0.032766 (0.935863 / 0.998606), rmse : 4.698034\n",
            "[403 image]\tber : 0.041668 (0.918807 / 0.997857), rmse : 4.714017\n",
            "[404 image]\tber : 0.055660 (0.891159 / 0.997520), rmse : 4.759573\n",
            "[405 image]\tber : 0.020324 (0.961492 / 0.997860), rmse : 4.759118\n",
            "[406 image]\tber : 0.025956 (0.951131 / 0.996958), rmse : 4.757964\n",
            "[407 image]\tber : 0.003508 (0.995405 / 0.997580), rmse : 8.143637\n",
            "[408 image]\tber : 0.001889 (0.996754 / 0.999468), rmse : 7.471817\n",
            "[409 image]\tber : 0.003425 (0.993538 / 0.999611), rmse : 6.161437\n",
            "[410 image]\tber : 0.004031 (0.992850 / 0.999088), rmse : 6.168838\n",
            "[411 image]\tber : 0.007988 (0.984863 / 0.999160), rmse : 6.170598\n",
            "[412 image]\tber : 0.005536 (0.989528 / 0.999401), rmse : 6.161861\n",
            "[413 image]\tber : 0.017627 (0.964953 / 0.999792), rmse : 5.363616\n",
            "[414 image]\tber : 0.038154 (0.924989 / 0.998704), rmse : 4.771566\n",
            "[415 image]\tber : 0.006200 (0.987852 / 0.999747), rmse : 4.283545\n",
            "[416 image]\tber : 0.022021 (0.966632 / 0.989326), rmse : 6.801393\n",
            "[417 image]\tber : 0.017234 (0.975772 / 0.989760), rmse : 6.816523\n",
            "[418 image]\tber : 0.025169 (0.955728 / 0.993935), rmse : 5.826979\n",
            "[419 image]\tber : 0.003866 (0.999416 / 0.992852), rmse : 11.134586\n",
            "[420 image]\tber : 0.003823 (0.999247 / 0.993106), rmse : 10.660139\n",
            "[421 image]\tber : 0.003097 (0.996790 / 0.997016), rmse : 7.340097\n",
            "[422 image]\tber : 0.003563 (0.996543 / 0.996332), rmse : 7.336042\n",
            "[423 image]\tber : 0.012662 (0.974972 / 0.999704), rmse : 5.667756\n",
            "[424 image]\tber : 0.017836 (0.975623 / 0.988706), rmse : 5.922229\n",
            "[425 image]\tber : 0.018985 (0.969184 / 0.992846), rmse : 5.728729\n",
            "[426 image]\tber : 0.013782 (0.984166 / 0.988271), rmse : 6.825804\n",
            "[427 image]\tber : 0.037218 (0.989101 / 0.936464), rmse : 7.467618\n",
            "[428 image]\tber : 0.084313 (0.954794 / 0.876580), rmse : 6.373552\n",
            "[429 image]\tber : 0.129635 (0.865927 / 0.874802), rmse : 6.227896\n",
            "[430 image]\tber : 0.086079 (0.960868 / 0.866974), rmse : 6.311060\n",
            "[431 image]\tber : 0.129732 (0.934592 / 0.805943), rmse : 7.673398\n",
            "[432 image]\tber : 0.081316 (0.945455 / 0.891913), rmse : 7.747913\n",
            "[433 image]\tber : 0.088726 (0.949056 / 0.873491), rmse : 7.975668\n",
            "[434 image]\tber : 0.090840 (0.942336 / 0.875985), rmse : 8.147851\n",
            "[435 image]\tber : 0.086342 (0.947656 / 0.879660), rmse : 8.145243\n",
            "[436 image]\tber : 0.087877 (0.951537 / 0.872709), rmse : 7.460733\n",
            "[437 image]\tber : 0.087267 (0.940463 / 0.885004), rmse : 6.466107\n",
            "[438 image]\tber : 0.120985 (0.959236 / 0.798794), rmse : 6.821266\n",
            "[439 image]\tber : 0.065992 (0.961801 / 0.906215), rmse : 7.888913\n",
            "[440 image]\tber : 0.090527 (0.937007 / 0.881939), rmse : 6.429526\n",
            "[441 image]\tber : 0.085787 (0.902705 / 0.925721), rmse : 7.402295\n",
            "[442 image]\tber : 0.072605 (0.986324 / 0.868467), rmse : 5.872241\n",
            "[443 image]\tber : 0.077351 (0.996768 / 0.848530), rmse : 5.905151\n",
            "[444 image]\tber : 0.101215 (0.984423 / 0.813147), rmse : 6.263566\n",
            "[445 image]\tber : 0.035902 (0.978994 / 0.949202), rmse : 8.708722\n",
            "[446 image]\tber : 0.038644 (0.979367 / 0.943345), rmse : 8.752102\n",
            "[447 image]\tber : 0.023435 (0.990329 / 0.962800), rmse : 10.751441\n",
            "[448 image]\tber : 0.078539 (0.987858 / 0.855063), rmse : 8.320502\n",
            "[449 image]\tber : 0.057842 (0.973526 / 0.910790), rmse : 7.689813\n",
            "[450 image]\tber : 0.059630 (0.940651 / 0.940088), rmse : 10.159967\n",
            "[451 image]\tber : 0.072956 (0.971147 / 0.882940), rmse : 6.448723\n",
            "[452 image]\tber : 0.005616 (0.998068 / 0.990700), rmse : 11.170755\n",
            "[453 image]\tber : 0.015411 (0.976842 / 0.992337), rmse : 4.878748\n",
            "[454 image]\tber : 0.018940 (0.970221 / 0.991900), rmse : 4.863557\n",
            "[455 image]\tber : 0.020442 (0.966741 / 0.992375), rmse : 4.904246\n",
            "[456 image]\tber : 0.020008 (0.966123 / 0.993861), rmse : 4.778937\n",
            "[457 image]\tber : 0.013537 (0.981877 / 0.991050), rmse : 4.755330\n",
            "[458 image]\tber : 0.007720 (0.988966 / 0.995594), rmse : 4.850173\n",
            "[459 image]\tber : 0.009956 (0.983491 / 0.996597), rmse : 4.733016\n",
            "[460 image]\tber : 0.007878 (0.987203 / 0.997040), rmse : 4.682268\n",
            "[461 image]\tber : 0.009395 (0.985934 / 0.995276), rmse : 4.677145\n",
            "[462 image]\tber : 0.003222 (0.998675 / 0.994880), rmse : 10.370291\n",
            "[463 image]\tber : 0.004450 (0.997194 / 0.993905), rmse : 8.916431\n",
            "[464 image]\tber : 0.002165 (0.998232 / 0.997438), rmse : 8.141266\n",
            "[465 image]\tber : 0.002229 (0.996750 / 0.998792), rmse : 6.349661\n",
            "[466 image]\tber : 0.002547 (0.995895 / 0.999012), rmse : 5.433484\n",
            "[467 image]\tber : 0.002260 (0.998414 / 0.997067), rmse : 7.712685\n",
            "[468 image]\tber : 0.001120 (0.999197 / 0.998564), rmse : 6.902430\n",
            "[469 image]\tber : 0.016718 (0.974312 / 0.992252), rmse : 4.861108\n",
            "[470 image]\tber : 0.301970 (0.635595 / 0.760466), rmse : 4.686040\n",
            "[471 image]\tber : 0.493534 (0.012932 / 1.000000), rmse : 2.794275\n",
            "[472 image]\tber : 0.444054 (0.111892 / 1.000000), rmse : 2.787408\n",
            "[473 image]\tber : 0.096286 (0.999327 / 0.808101), rmse : 7.781319\n",
            "[474 image]\tber : 0.181963 (0.940621 / 0.695453), rmse : 6.094240\n",
            "[475 image]\tber : 0.187451 (0.952764 / 0.672334), rmse : 6.664651\n",
            "[476 image]\tber : 0.148766 (0.983654 / 0.718814), rmse : 6.985927\n",
            "[477 image]\tber : 0.116348 (0.975821 / 0.791482), rmse : 6.719532\n",
            "[478 image]\tber : 0.136497 (0.988103 / 0.738904), rmse : 6.917683\n",
            "[479 image]\tber : 0.159322 (0.974250 / 0.707107), rmse : 6.831571\n",
            "[480 image]\tber : 0.146087 (0.984260 / 0.723566), rmse : 7.117536\n",
            "[481 image]\tber : 0.106686 (0.994673 / 0.791955), rmse : 6.805035\n",
            "[482 image]\tber : 0.117431 (0.993935 / 0.771203), rmse : 7.759162\n",
            "[483 image]\tber : 0.111052 (0.996316 / 0.781580), rmse : 8.538466\n",
            "[484 image]\tber : 0.106161 (0.993694 / 0.793984), rmse : 7.989866\n",
            "[485 image]\tber : 0.095924 (0.991162 / 0.816989), rmse : 8.246866\n",
            "[486 image]\tber : 0.092602 (0.984938 / 0.829859), rmse : 8.650511\n",
            "[487 image]\tber : 0.098266 (0.987213 / 0.816256), rmse : 7.594921\n",
            "[488 image]\tber : 0.108740 (0.987625 / 0.794895), rmse : 7.073491\n",
            "[489 image]\tber : 0.063783 (0.874367 / 0.998068), rmse : 4.492527\n",
            "[490 image]\tber : 0.250222 (0.499680 / 0.999877), rmse : 4.119070\n",
            "[491 image]\tber : 0.425426 (0.149486 / 0.999662), rmse : 4.221781\n",
            "[492 image]\tber : 0.335531 (0.330452 / 0.998485), rmse : 4.126650\n",
            "[493 image]\tber : 0.354849 (0.290698 / 0.999604), rmse : 3.898943\n",
            "[494 image]\tber : 0.328693 (0.348018 / 0.994596), rmse : 4.597393\n",
            "[495 image]\tber : 0.483598 (0.033983 / 0.998822), rmse : 4.638722\n",
            "[496 image]\tber : 0.344463 (0.312227 / 0.998847), rmse : 4.602303\n",
            "[497 image]\tber : 0.178943 (0.642344 / 0.999771), rmse : 3.649509\n",
            "[498 image]\tber : 0.031400 (0.937606 / 0.999595), rmse : 2.905721\n",
            "[499 image]\tber : 0.061053 (0.879381 / 0.998512), rmse : 4.030289\n",
            "[500 image]\tber : 0.011080 (0.977929 / 0.999911), rmse : 3.288301\n",
            "[501 image]\tber : 0.017112 (0.969587 / 0.996189), rmse : 3.931725\n",
            "[502 image]\tber : 0.010737 (0.982739 / 0.995787), rmse : 3.495811\n",
            "[503 image]\tber : 0.052138 (0.895934 / 0.999790), rmse : 3.276736\n",
            "[504 image]\tber : 0.032219 (0.936605 / 0.998956), rmse : 3.379044\n",
            "[505 image]\tber : 0.023155 (0.954675 / 0.999014), rmse : 2.755954\n",
            "[506 image]\tber : 0.009728 (0.983388 / 0.997156), rmse : 3.487048\n",
            "[507 image]\tber : 0.005116 (0.990509 / 0.999258), rmse : 3.722652\n",
            "[508 image]\tber : 0.010420 (0.980660 / 0.998500), rmse : 4.280144\n",
            "[509 image]\tber : 0.022767 (0.955032 / 0.999435), rmse : 4.805492\n",
            "[510 image]\tber : 0.096536 (0.807462 / 0.999467), rmse : 4.692553\n",
            "[511 image]\tber : 0.242922 (0.514996 / 0.999160), rmse : 4.578127\n",
            "[512 image]\tber : 0.034591 (0.932121 / 0.998697), rmse : 4.054494\n",
            "[513 image]\tber : 0.498495 (0.003010 / 1.000000), rmse : 3.319085\n",
            "[514 image]\tber : 0.481937 (0.036126 / 1.000000), rmse : 3.024086\n",
            "[515 image]\tber : 0.487687 (0.024625 / 1.000000), rmse : 3.106325\n",
            "[516 image]\tber : 0.460010 (0.090117 / 0.989864), rmse : 4.571354\n",
            "[517 image]\tber : 0.468852 (0.084821 / 0.977476), rmse : 4.122546\n",
            "[518 image]\tber : 0.388907 (0.245719 / 0.976467), rmse : 3.739131\n",
            "[519 image]\tber : 0.460725 (0.113035 / 0.965516), rmse : 3.658280\n",
            "[520 image]\tber : 0.490409 (0.075051 / 0.944130), rmse : 3.324563\n",
            "[521 image]\tber : 0.478778 (0.104434 / 0.938010), rmse : 3.598967\n",
            "[522 image]\tber : 0.424821 (0.209709 / 0.940649), rmse : 3.254732\n",
            "[523 image]\tber : 0.002621 (0.995948 / 0.998810), rmse : 6.158800\n",
            "[524 image]\tber : 0.002827 (0.995155 / 0.999191), rmse : 6.056926\n",
            "[525 image]\tber : 0.009369 (0.982145 / 0.999117), rmse : 4.813922\n",
            "[526 image]\tber : 0.009037 (0.983263 / 0.998662), rmse : 5.079010\n",
            "[527 image]\tber : 0.035640 (0.928903 / 0.999816), rmse : 3.237544\n",
            "[528 image]\tber : 0.037105 (0.925908 / 0.999881), rmse : 3.228725\n",
            "[529 image]\tber : 0.014060 (0.972103 / 0.999778), rmse : 3.556102\n",
            "[530 image]\tber : 0.013079 (0.974169 / 0.999673), rmse : 3.604075\n",
            "[531 image]\tber : 0.007181 (0.986406 / 0.999232), rmse : 3.660286\n",
            "[532 image]\tber : 0.068159 (0.895452 / 0.968230), rmse : 9.014970\n",
            "[533 image]\tber : 0.033257 (0.990655 / 0.942831), rmse : 12.123814\n",
            "[534 image]\tber : 0.038049 (0.965512 / 0.958389), rmse : 12.181967\n",
            "[535 image]\tber : 0.056217 (0.958859 / 0.928706), rmse : 9.587489\n",
            "[536 image]\tber : 0.050134 (0.975280 / 0.924451), rmse : 9.512383\n",
            "[537 image]\tber : 0.037236 (0.985843 / 0.939684), rmse : 8.640972\n",
            "[538 image]\tber : 0.046004 (0.945811 / 0.962181), rmse : 8.648531\n",
            "[539 image]\tber : 0.045780 (0.949448 / 0.958992), rmse : 8.819487\n",
            "[540 image]\tber : 0.034508 (0.973807 / 0.957176), rmse : 10.077153\n",
            "DONE============\n",
            "BER : 0.076120\n",
            "sens : 0.899178\n",
            "spec : 0.948582\n",
            "RMSE : 5.594315\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}